---
title: "Poorly Anonymized NYC Taxi Data"
description: |
   Examining Ethics and Power in a Data Science Context
author: Thomas Matheis
date: April 13, 2025
format: html
execute:
  warning: false
  message: false
---

# Background

In 2014, New York City released a large dataset containing the details of over 173 million taxi trips. The decision to release the dataset followed a Freedom of Information request submitted by Chris Wong, an open data activist. This dataset included pick-up and drop-off locations, trip times, fares, and “anonymized” driver license numbers. However, Ars Technica later reported that the anonymization was incomplete, making it surprisingly easy to mathematically reverse-engineer and uncover individual drivers’ identities in just a few hours (Goodin 2014). Meanwhile, The Guardian warned that such revelations could compromise not just the drivers' privacy, but high-profile passengers as well (Hern 2014). This situation highlights a significant topic of data science ethics. On one hand, open data can be incredibly beneficial for urban planning, traffic analysis, and academic research, which may have been the original intention of Chris Wong. On the other hand, the poor anonymization of the data put personal information at risk. As details like trip routes and tips suddenly became exposed to the community, drivers and their passengers had to worry about being identified and facing public scrutiny. This dilemma highlights how the power to collect and share data can inadvertently harm the very people it is meant to benefit.

# Data Collection and Consent

In data science, data collection refers to gathering large amounts of information to be used for analysis. This commonly includes people, which introduces the problem that those whose data is being collected consent to it or even know about it. In this example, the New York City Taxi and Limousine Commission (TLC) legally collected taxi trip data for regulatory purposes, so there was no violation in the initial data gathering. This brings up the differences between legally-collected data and ethically-collected data. For example, many passengers and potentially even drivers may not have even known that data was being collected on them during every trip, which raises consent and privacy issues despite the information being collected lawfully. While the TLC did comply with the Freedom of Information request, it’s unclear if drivers were ever fully informed that details, like how much they earned and where they drove, were even a part of the dataset being released. Additionally, Ars Technica points out the existing privacy concerns revolving around the usage of GPS to track taxi driver's trips and fares. (Goodin 2014) In this sense, the power dynamics heavily favor the TLC, leaving their drivers, and especially passengers, with little say over how their information is used.

# Data Anonymization

The practice of removing personal identifiers from a dataset is known as data anonymization, and it is used to prevent individuals from being linked to any data that may have been collected about them. It becomes a major issue when anonymization techniques are weak and it becomes easy to identify people by cross-referencing with other datasets. As mentioned earlier, though the dataset was presented as “anonymized,” Vijay Pandurangan, a software developer, soon discovered that the same algorithm used to hash driver IDs could be used to reverse engineer and identify every medallion and license number in the span of a few hours (Hern 2014). This meant anyone interested could decode the hashed data and cross-reference it with TLC resources to match medallions to specific drivers. The Guardian warned that even passengers’ identities could be inferred with enough cross-referencing, such as matching time and location details to public events (Hern 2014). New York City officials failed to protect their taxi driver's privacy, with Ars Technica emphasizing that there were various other ways to successfully anonymize the data, for example, assigning "a random number to each hack license number and medallion number and use the substitute numbers throughout the disclosure" (Goodin 2014). This lack of anonymization shows how crucial it is to implement efficient privacy measures, especially when releasing data regarding people’s daily lives and routines.

# Permission for Using the Data

This was touched on in the last paragraph, but in general, permission to use data determines who can collect, access, and distribute said data. A major concern is determining if their is are ethical standards to consider even if one has a legal right to distribute data. In this scenario, The Freedom of Information Law (FOIL) required New York City officials to release some version of the requested data (Hern 2014). However, data science ethics suggest that an organization should go beyond minimum legal requirements and proactively protect individual privacy. The real question is whether the TLC even considered safer methods, such as providing less detailed data or seeking better encryption techniques, before making the dataset public (Goodin 2014). By not doing so, the agency unintentionally enabled widespread privacy invasions, effectively granting permission for others to dig into drivers’ details, which was likely never the original intent.

# Unintended Uses of the Data

Once data is made public, it can be used in ways the original collectors never anticipated. For example, in 2016 census data was used to create a function that predicted an individual's race based on their last name and address, which employers could then use to discriminate against those who apply for jobs. In this case, the de-anonymized taxi data made it easy to identify where taxi drivers or passengers lived, and even how much money they made/tipped, information that could be used to easily target an individual. While some of the uses might be considered intriguing or even beneficial for academic research, many can be seen as a complete breach of privacy. As The Guardian stated, “anonymized” data can quickly become weaponized in the wrong hands, casting a dark light on how easily open data can turn into targeted surveillance (Hern 2014). This highlights how crucial it is to carefully consider the ethics of a situation to ensure the privacy and safety of the involved parties.

# Citations

Goodin, Dan. 2014. “Poorly Anonymized Logs Reveal NYC Cab Drivers’ Detailed Whereabouts.” Ars Technica, June 26. https://arstechnica.com/tech-policy/2014/06/poorly-anonymized-logs-reveal-nyc-cab-drivers-detailed-whereabouts/.

Hern, Alex. 2014. “New York Taxi Details Whizz Around after ‘Anonymised’ Data Release.” The Guardian, June 27. https://www.theguardian.com/technology/2014/jun/27/new-york-taxi-details-anonymised-data-researchers-warn.
