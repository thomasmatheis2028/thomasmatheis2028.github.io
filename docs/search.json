[
  {
    "objectID": "ufo.html",
    "href": "ufo.html",
    "title": "UFO Sightings",
    "section": "",
    "text": "This data set consists of over 80,000 documented UFO sightings all over the world. Some variables include country, region, city, time, shape, and length of encounter. This graph compares the number of encounters between each country in the data set, highlighting the stark difference between the amount of sightings in the United States compared to everyone else.\n\n\n\n\n\n\n\n\n\nThe TidyTuesday data can be found at: https://github.com/rfordatascience/tidytuesday/tree/main/data/2019/2019-06-25\nThe original data set, from NUFORC (The National UFO Reporting Center), can be found at: https://nuforc.org/databank/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thomas Matheis",
    "section": "",
    "text": "Hey! I’m Tommy, a current first year at Pomona College. I love math and data science, and I’m excited to build upon my current knowledge in those fields. Outside of the classroom, I am a diver on Pomona-Pitzer’s Swimming & Diving team. My hobbies include listening to indie music, going on long drives, and mountain biking."
  },
  {
    "objectID": "spotify.html",
    "href": "spotify.html",
    "title": "Spotify",
    "section": "",
    "text": "After viewing my 2024 Spotify Wrapped (pictured above), I questioned the validity of the results that were displayed. Was Drake really one of my top artists? Did I really listen to Dominic Fike more than Twenty One Pilots? Using Spotify’s “Data Request” feature, I was able to receive copies of my streaming history from November 4th, 2023 to November 4th, 2024.\nFirst, I merged the set of three JSON files I received, and converted them into a single csv file to make it easier to work with, reading the csv into a data table:\n\ndf1 &lt;- fromJSON(\"StreamingHistory_music_0.json\")\ndf2 &lt;- fromJSON(\"StreamingHistory_music_1.json\")\ndf3 &lt;- fromJSON(\"StreamingHistory_music_2.json\")\n\nmerged_df &lt;- bind_rows(df1, df2, df3)\n\nwrite.csv(merged_df, \"spotify_data.csv\", row.names = FALSE)\nspotify_csv &lt;- read_csv(\"spotify_data.csv\")\nspotify_data &lt;- spotify_csv |&gt; mutate(endTime = as.Date(endTime))\nhead(spotify_data, 5)\n\n# A tibble: 5 × 4\n  endTime    artistName        trackName      msPlayed\n  &lt;date&gt;     &lt;chr&gt;             &lt;chr&gt;             &lt;dbl&gt;\n1 2023-10-17 Bad Bunny         MONACO            69369\n2 2023-11-04 Twenty One Pilots Heavydirtysoul     2944\n3 2023-11-04 Twenty One Pilots Hometown            874\n4 2023-11-04 Twenty One Pilots Levitate            768\n5 2023-11-04 Twenty One Pilots Ride                917\n\n\nIt can be seen that the “artistsName” and “trackName” variables both contain character strings, which is what we’ll be working with. Just to simplify things, I converted the “endTime” variable from &lt;S3: POSIXct&gt; to &lt;date&gt;. The variable “msPlayed” contains &lt;dbl&gt; values which measure the time listened to a song measured in milliseconds.\nNow we can being working with the strings!\nOne observation I made in the dataset was that many songs have a feature artist, and therefore have “(feat. ‘artist name’)” in the title. We can clean the dataset by removing the features from the track names!\nFirst, let’s look at some examples of what this looks like, using str_detect:\n\nfeature_example &lt;- spotify_data |&gt;\n  filter(str_detect(trackName,\"\\\\(feat.*\\\\)\")) |&gt;\n  select(artistName, trackName)\nhead(feature_example, 5)\n\n# A tibble: 5 × 2\n  artistName             trackName                                        \n  &lt;chr&gt;                  &lt;chr&gt;                                            \n1 Lil Uzi Vert           Neon Guts (feat. Pharrell Williams)              \n2 Metro Boomin           Space Cadet (feat. Gunna)                        \n3 Metro Boomin           Too Many Nights (feat. Don Toliver & with Future)\n4 Gunna                  P power (feat. Drake)                            \n5 A Boogie Wit da Hoodie Drowning (feat. Kodak Black)                     \n\n\nNow, using str_relpace_all to remove all features, and str_trim to remove all spaces after the string:\n\nspotify_data_nofeat &lt;- spotify_data |&gt;\n  mutate(trackName = str_replace_all(trackName,\"\\\\(feat.*\\\\)\", \"\")) |&gt;\n  mutate(trackName = str_trim(trackName))\n\nUsing the same five songs as before, we can now show how the features have been removed:\n\nfeature_example1 &lt;- spotify_data_nofeat |&gt;\n  filter(str_detect(trackName, \"Neon Guts|Space Cadet|Too Many Nights|P power|Drowning\")) |&gt;\n  select(artistName, trackName)\nhead(feature_example1,5)\n\n# A tibble: 5 × 2\n  artistName             trackName      \n  &lt;chr&gt;                  &lt;chr&gt;          \n1 Lil Uzi Vert           Neon Guts      \n2 Metro Boomin           Space Cadet    \n3 Metro Boomin           Too Many Nights\n4 Gunna                  P power        \n5 A Boogie Wit da Hoodie Drowning       \n\n\nBoom! No features! Let’s look at some rows in the data and see if it looks better:\n\nfeature_example2 &lt;- spotify_data_nofeat |&gt;\n  select(artistName, trackName)\nfeature_example2[41:47,]\n\n# A tibble: 7 × 2\n  artistName             trackName                                              \n  &lt;chr&gt;                  &lt;chr&gt;                                                  \n1 A Boogie Wit da Hoodie Drowning                                               \n2 Metro Boomin           Superhero (Heroes & Villains) [with Future & Chris Bro…\n3 Chief Keef             Love Sosa                                              \n4 Drake                  Rich Flex                                              \n5 Future                 Solo                                                   \n6 Metro Boomin           Trance (with Travis Scott & Young Thug)                \n7 Mac Miller             Ayye                                                   \n\n\nUh oh! We didn’t account for features that use “with” instead of “feat.” Also, we can see that some songs use brackets while others use parenthesis. We can use lookarounds and some more regular expressions to account for the variations of “with” that song titles use:\n\nspotify_data_nofeat &lt;- spotify_data_nofeat |&gt;\n  mutate(trackName = str_replace_all(trackName,\"(?&lt;=\\\\s)(\\\\(.*?\\\\)|\\\\[.*?\\\\]|\\\\swith\\\\s)(.*)\", \"\")) |&gt;\n  mutate(trackName = str_trim(trackName))\n\nThe escapes make it look a little messy, but this uses a positive lookbehind to check for a space before matching any text in parenthesis, brackets, or simply “with” with any spaces around it. We replace all of the matches to this pattern with an empty space. Here’s our example again, displaying the updated results:\n\nfeature_example2 &lt;- spotify_data_nofeat |&gt;\n  select(artistName, trackName)\nfeature_example2[41:47,]\n\n# A tibble: 7 × 2\n  artistName             trackName\n  &lt;chr&gt;                  &lt;chr&gt;    \n1 A Boogie Wit da Hoodie Drowning \n2 Metro Boomin           Superhero\n3 Chief Keef             Love Sosa\n4 Drake                  Rich Flex\n5 Future                 Solo     \n6 Metro Boomin           Trance   \n7 Mac Miller             Ayye     \n\n\nThis looks much cleaner now.\nNow that we have a clean data frame containing the artist name, song name, date, and amount of time listened too, we can make some graphs!\nFirst, I want to look at my top five artists by listening time. To do this, we need to add up the total play time each artist received:\n\nmsPlayed_artist &lt;- spotify_data_nofeat |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_msPlayed = sum(msPlayed)) |&gt;\n  arrange(desc(total_msPlayed)) |&gt;\n  head(5)\n\nTime to graph:\n\nggplot(msPlayed_artist, aes(x = fct_reorder(artistName, total_msPlayed), y = total_msPlayed, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Listening Time (ms)\",\n    title = \"My Top Five Spotify Artists by Listening Time\",\n    fill = \"Artist\"\n  ) + coord_flip()\n\n\n\n\n\n\n\n\nWell that’s odd, it looks like my order doesn’t match with what Spotify told me. Twenty One Pilots has significantly more total listening time than Dominic Fike, yet Dominic Fike appears first on the official list.\nWhat if we look at total songs played instead of listening time:\n\ntotal_songs_artist &lt;- spotify_data_nofeat |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_songs = n()) |&gt;\n  arrange(desc(total_songs)) |&gt;\n  head(5)\n\nOnce again graphing:\n\nggplot(total_songs_artist, aes(x = fct_reorder(artistName, total_songs), y = total_songs, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Songs Played\",\n    title = \"My Top Five Spotify Artists by Total Songs Played\",\n    fill = \"Artist\"\n  ) + coord_flip()\n\n\n\n\n\n\n\n\nWell, at least this tells us that something isn’t quite right with how Spotify determines a user’s top artists. Our top 5 artists measured by total songs played is in the same order as when we measure by total listening time, however this time Twenty One Pilots and Dominic Fike are much closer. This tells me that Drake for sure belonged on my Spotify Wrapped, as he ranked 3rd in total songs played and total listening time. I also confirmed my suspicion that I listened to more Twenty One Pilots than any other artist, especially when looking at listening time. One reason for the discrepancy could be the time frame that Spotify uses. My data begins in November of 2023 and ends in November of 2024. It could be possible that Spotify uses data beginning on January 1st of each year. We can use only the songs from January 1st and onwards to see if it significantly changes our results.\nRepeating the process for listening time:\n\nspotify_2024_only1 &lt;- spotify_data_nofeat |&gt;\n  filter(endTime &gt;= \"2024-01-01\") |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_msPlayed = sum(msPlayed)) |&gt;\n  arrange(desc(total_msPlayed)) |&gt;\n  head(5)\n\nggplot(spotify_2024_only1, aes(x = fct_reorder(artistName, total_msPlayed), y = total_msPlayed, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Listening Time (ms)\",\n    title = \"My Top Five Spotify Artists by Listening Time for 2024\",\n    fill = \"Artist\"\n  ) + coord_flip()\n\n\n\n\n\n\n\n\nRepeating the process for total songs played:\n\nspotify_2024_only2 &lt;- spotify_data_nofeat |&gt;\n  filter(endTime &gt;= \"2024-01-01\") |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_songs = n()) |&gt;\n  arrange(desc(total_songs)) |&gt;\n  head(5)\n\nggplot(spotify_2024_only2, aes(x = fct_reorder(artistName, total_songs), y = total_songs, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Songs Played\",\n    title = \"My Top Five Spotify Artists by Total Songs Played for 2024\",\n    fill = \"Artist\"\n  ) + coord_flip()\n\n\n\n\n\n\n\n\nThis data is closer to the official Spotify Wrapped, though still not quite right. When looking at total listening time for 2024, Don Toliver pushes his way up to third on the list, which is where he was officialy ranked. However, when looking at total songs played for 2024, the only time Dominic Fike has outranked Twenty One Pilots, Don Toliver falls places fifth by almost 500 songs.\nOverall, Spotify Wrapped does a good-enough job in the sense that it correctly identified my top artists artists for both total listening time and total songs played. However, the order that it ranked my top five artsits in doesn’t seem to quite line up with my streaming history data. However, as we found above, the time frame of the data can make a big difference in the rankings. My data contained history up until November 4th, and it is likely that Spotify Wrapped, which released on December 4th, utilized that extra month of streaming history that was not included in the files I received. This extra month of missing data could explain some of the differences in rankings I found.\nTo view the data:\nThe three individual .JSON files of my Spotify streaming history and the merged .csv file can be accessed on the public repository for this website!\nhttps://github.com/thomasmatheis2028/thomasmatheis2028.github.io"
  },
  {
    "objectID": "starbucks.html",
    "href": "starbucks.html",
    "title": "Starbucks",
    "section": "",
    "text": "This is the data set from Starbucks’ official 2021 nutritional information. Steamed milk data is omitted from this data set. The vizualization displays the relationship between the amount of sugar in a beverage and its calories. The color is organized by type of milk. It can be seen that drinks with more sugar typically have a higher calorie count.\n\n\n\n\n\n\n\n\n\nThe TidyTuesday data can be found at: https://github.com/rfordatascience/tidytuesday/tree/main/data/2021/2021-12-21\nThe current nutritional information, from the official Starbucks website, can be found at: https://www.starbucks.ie/sites/starbucks-ie-pwa/files/2025-01/Winter%20Beverage%20Nutritionals%20.pdf"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Guessing on a Test",
    "section": "",
    "text": "Many students have considered the option at once in their academic careers: “Do I simply just guess on every question of the test?” While achieving a perfect score by guessing on a test is an amazing feat, it is pretty simple to calculate. Assuming multiple-choice tests with 4 choices for each question and 10 questions, this simulation study will determine the probability of passing a test by guessing on every question. In this scenario, passing will be considered a C- (70%) or above. The function will return True or False depending on whether or not the test passed. Using a logical map, the function will be iterated 1000 times to determine a probability of passing.\n\ntest &lt;- function(questions, choices, grade){\n  num_correct &lt;- sum(sample(1:choices, questions, replace = TRUE) == 1) \n  return((num_correct / questions) &gt;= grade)\n}\n\nset.seed(47)\ntest_simulation &lt;- map_lgl(1:1000, ~ test(10, 4, .7)) |&gt;\n  mean() |&gt;\n  print()\n\n[1] 0.007\n\n\nFor this simulation, 7 out of 1000 tests passed when guessing on all 10 questions, giving a probability of about 0.7%. Not a very great strategy. We can also test different factors, changing the grade required to “pass”, the number of questions, and the number of choices for each question. Let’s do a few more tests where only 60% is required to pass.\n10 Questions, 4 Choices, 60% to Pass:\n\nset.seed(47)\ntest_simulation &lt;- map_lgl(1:1000, ~ test(10, 4, .6)) |&gt;\n  mean() |&gt;\n  print()\n\n[1] 0.026\n\n\nA little better, 2.6% chance of passing, but only if you’re OK with a 60%.\n20 Questions, 4 Choices, 60% to Pass:\n\nset.seed(47)\ntest_simulation &lt;- map_lgl(1:1000, ~ test(20, 4, .6)) |&gt;\n  mean() |&gt;\n  print()\n\n[1] 0\n\n\nYikes, just increasing the number of questions to 20 decreases the probability to a 0% chance of passing if you’re just guessing.\nHere is a plot displaying how the number of questions affects the probability of passing, when only 60% is needed to pass:\n\n#Re-writing our test_simulation as a function\n\npass_probability &lt;- function(num_questions, num_simulations, num_choices, pct_grade){\n  test_simulation &lt;- map_lgl(1:num_simulations, ~ test(num_questions, num_choices, pct_grade))\n  return(mean(test_simulation))\n}\n\nset.seed(47)\nresults &lt;- map_dbl(1:20, ~ pass_probability(.x, 1000, 4, .60))\n\nresults_table &lt;- tibble(results) |&gt; \n  mutate(questions = c(1:20)) |&gt;\n  as.data.frame()\n\nggplot(results_table, aes(x = questions, y = results)) +\n  geom_smooth(se = FALSE) +\n  geom_point() +\n  geom_line() +\n  labs(\n    x = \"Number of Questions\",\n    y = \"Probability of Passing\",\n    title = \"Probability of Passing a Test by Guessing\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nAs seen above, as the number of questions on a test increases, the probability of passing a test by guessing on every question decreases significantly. For any number of questions beyond 10, it becomes extremely close to 0. The blue line represents the overall trend in the data.\nOverall, the simulation study found that guessing on a test is simply not a good strategy, even when just trying to pass a test. When simulating 1000 times, a probability of 0.7% was found for getting 70% on a 10 question test by guessing. When a 60% was required to pass there was a 2.6% chance, and when increasing the number of questions to 20 there was a 0% chance of passing. Plotting the results of simulating different numbers of questions on the tests revealed the inverse relationship between probability of passing and the number of questions."
  }
]