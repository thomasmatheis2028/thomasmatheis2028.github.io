[
  {
    "objectID": "ufo.html",
    "href": "ufo.html",
    "title": "UFO Sightings",
    "section": "",
    "text": "This data set consists of over 80,000 documented UFO sightings all over the world. Some variables include country, region, city, time, shape, and length of encounter. This graph compares the number of encounters between each country in the data set, highlighting the stark difference between the amount of sightings in the United States compared to everyone else.\n\n\nShow the code\nlibrary(tidyverse)\nufo &lt;- readr::read_csv(\"ufo_sightings.csv\")\nggplot(ufo, aes(x = country, fill = country)) +\n  geom_bar(na.rm = TRUE) +\n  labs(\n    x = \"Country\",\n    y = \"Number of Sightings\",\n    title = \"Number of UFO Sightings by Country\",\n    subtitle = \"n &gt; 80,000\",\n    fill = \"Country\"\n  ) + theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nThe TidyTuesday data can be found at: https://github.com/rfordatascience/tidytuesday/tree/main/data/2019/2019-06-25\nThis project utilized a data set uploaded to GitHub by Sigmond Axel, who had cleaned the raw data from NUFORC (The National UFO Reporting Center), which can be found at: https://nuforc.org/databank/"
  },
  {
    "objectID": "athletics.html",
    "href": "athletics.html",
    "title": "Pomona-Pitzer Athletic Spending",
    "section": "",
    "text": "This dataset includes the spending of all Pomona-Pitzer athletic teams, including the number of athletes on each team, for both the 2022-2023 and 2023-2024 seasons. This graph compares the spending for all of the teams that have both men and women programs (for example, excluding sports such as baseball, football, softball, etc.) to highlight any key differences in spending between the programs. The raw data was collected from both the Pomona-Pitzer Athletics website and Equity in Athletics Data Analysis. For a more in-depth breakdown of the gender disparities found in Pomona-Pitzer athletics, check out The Student Life article “P-P sport expenses: How rosters and post season travel affect the budget,” written by Jun Kwon and William Walz.\n\n\nShow the code\nppeada &lt;- read_csv(\"/Users/tommy/Desktop/Intro to Stats/Intro to Stats/ppeada.csv\")\nppeada23 &lt;- read_csv(\"/Users/tommy/Desktop/Intro to Stats/Intro to Stats/ppeada23.csv\")\n\nppeada1 &lt;- ppeada |&gt; \n  filter(sport != \"Baseball\", sport != \"Football\", sport != \"Softball\", sport != \"Volleyball\", sport != \"Lacrosse\")\nppeada2 &lt;- ppeada23 |&gt; \n  filter(sport != \"Baseball\", sport != \"Football\", sport != \"Softball\", sport != \"Volleyball\", sport != \"Lacrosse\")\n\n\n\n\nShow the code\nggplot(ppeada1, aes(x = sport, y = expenses, fill = sex)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  scale_fill_manual(\n    values = c(\n      \"M\"   = \"#0057b8\",   \n      \"F\" = \"#f7941d\"    \n    ),\n    name = \"Team\"\n  ) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    x = \"\", y = \"Proportion of Funding\",\n    title = \"Proportions of Funding Between Men's and Women's Teams by Sport\",\n    subtitle = \"2023-2024\"\n  ) +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(ppeada2, aes(x = sport, y = expenses, fill = sex)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  scale_fill_manual(\n    values = c(\n      \"M\"   = \"#0057b8\",   \n      \"F\" = \"#f7941d\"  \n    ),\n    name = \"Team\"\n  ) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    x = \"\", y = \"Proportion of Funding\",\n    title = \"Proportions of Funding Between Men's and Women's Teams by Sport\",\n    subtitle = \"2022-2023\"\n  ) +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nThe Pomona-Pitzer Athletics 2023-2024 EADA Report can be found at: https://sagehens.com/documents/2024/10/22/EADA_Report_23-24_FINAL.pdf\nThe 2022-2023 report can be found directly on EADA’s website: https://ope.ed.gov/athletics/#/institution/details\nKwon, Jun. Walz, William. 2025. “P-P sport expenses: How rosters and post season travel affect the budget.” The Student Life Newspaper, April 25. https://tsl.news/p-p-sport-expenses-how-rosters-and-post-season-travel-affect-the-budget/."
  },
  {
    "objectID": "hockey.html",
    "href": "hockey.html",
    "title": "Hockey Player Birth Months",
    "section": "",
    "text": "Introduction\n“Success” is a term often associated with hard work and talent, and in athletics, defines the career of an individual. In life, our society tends to measure people by how “successful” they are, comparing them to the wealthy and upper class. On the surface, success seems like a goal, something that can be achieved with just the right amount of dedication. Malcom Gladwell, a Canadian journalist, argues a different standpoint: success is determined by countless factors, many times out of an individual’s own control. One specific example mentioned in his 2008 book \\(\\textit{Outliers}\\) revolves around Canadian hockey players, and how athletes born earlier in the year tend to become professional athletes more often than those born in later months. The main cause of this trend can be attributed to the January 1st age cutoff in junior hockey leagues, where players born in earlier months usually end up dominating those born later in the year due to physical differences that become magnified each season. In an age where athletics are more competitive than ever, it is extremely important to mantain equity in junior-level sports.\nNarrowing in on this supposed trend among professional Canadian hockey players, this project will investigate the distribution of birthdays, examining whether or not they are evenly distributed throughout the year. Comparing birthdays of Canadian NHL players to simulated data where birthday distribution is fixed, we will be able to make a decision regarding how much of an effect it has on athletic success. Section 2 of this project will describe the methods and details of the data set being used, along with various variations and summaries of said data. Section 3 presents the results, using statistical inference to determine the implications it has on the overall investigation. The final section provides a conclusion to this project, summarizing the findings of the project, providing an insight into possible errors and future directions of this topics.\n\n\nMethods\nTo properly test Malcom Gladwell’s claim regarding early birth month advantages in hockey, we must first examine real world data. To limit the sample size to a manageable number, all NHL players with a last name beginning with the letter “L” were extracted from HockeyDB, a public online database for professional hockey. After filtering the data set to only include recent Canadian players (after 1975), 88 athletes remained, with variables consisting of their name, position, birthday, birthplace, and seasons.\nThe visual below displays the birthday for each athlete in the data set, where the x-axis represents every year after 1975, the y-axis is the day of the year (1 - 365), and the red line marks the halfway point of the year:\n\n\nShow the code\nsim_df &lt;- as.data.frame(sim)      # making data table with the given simulated data \"sim\"\n\nsim_df &lt;- sim_df |&gt; \n  mutate(sim_num = row_number()) |&gt;\n  pivot_longer(cols = -sim_num, names_to = \"quarter\", values_to = \"count\") |&gt;\n  mutate(z_score = (count-mu)/sigma, z_score_squared = z_score^2)\n\nsim_summary &lt;- sim_df |&gt;\n  group_by(sim_num) |&gt;\n  summarize(sum_z_squared = sum(z_score_squared))\n\np_value &lt;- mean(sim_summary$sum_z_squared &gt;= real_sum_z_sq)\n\n#Utilizing a given data-set \"Bdays.recent\"\n\nggplot(Bdays.recent, aes(x = year, y = NumDays)) +\n  geom_point(color = \"black\") +\n  geom_hline(yintercept = 182.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Year\",\n    y = \"Day of the Year\",\n    title = \"Birthdays of Canadian NHL Players with Last Name Beginning with \\\"L\\\"\",\n    subtitle = \"n = 88\"\n  ) + theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nEven before any statistical analysis, one can already observe more athletes having birthdays in the first half of the year. Though it may seem tempting to simply conclude Gladwell was correct by just looking at a visual representation of the data, the exact quantity of birthdays and probability of observing this exact data is unclear.\nIn order to further investigate Malcom Gladwell’s claim, the data was divided up so that each athlete’s birthday was assigned a value based off of the quarter of the year it fell in (1, 2, 3, or 4). Computing the total sum of athletes born in each quarter produced four values:\n\\(\\bullet\\) 26 in the first quarter\n\\(\\bullet\\) 36 in the second quarter\n\\(\\bullet\\) 12 in the third quarter\n\\(\\bullet\\) 14 in the fourth quarter\nTo determine whether or not these values deviate significantly from the null hypothesis, where the probability of a randomly selected athlete being born in each quarter is 0.25, a hypothesis test will be conducted using 1,000 randomly generated simulations.\nThis data set is not a randomly selected sample of Canadian hockey players; it only consists of Canadian NHL athletes born after 1975 with a last name beginning with a specific letter. We threw out all players born before 1976, eliminating hundreds of points of data. Additionally, if we are analyzing how earlier birthdays result in more professional hockey players than later birthdays, but we only look at professional hockey players, it may not provide accurate information about Canadian hockey players as a whole and how birth month affects overall participation and advancement in junior levels of hockey. However, because a player’s last name should not correlate to the time of the year they are born in, and our sample size is large enough to determine patterns in hockey performance, we can still make the assumption that this sample should represent the larger population of Canadian hockey players.\n\n\nData Analysis\nTo determine whether or not the birthdays of professional Canadian hockey players are evenly distributed throughout the year, we can conduct a hypothesis test. The null-hypothesis, \\(H_0\\), states that birthdays should be evenly distributed, so that 25% of players have birthdays in each quarter. In order to make an adequate comparison between the real data and the simulated data, we will find the Z-score for each quarter, square them to ensure positive values and emphasize differences, and find the sum for each of the four quarters. This will give us a single value comprising of the sum of the squared Z-scores for each of the four quarters. We can repeat this process for each trial of the simulation.\nThe bar plot below compares the observed number of athletes born in each quarter to the expected number of athletes born in each quarter:\n\n\nShow the code\n# Create a data frame for observed vs. expected counts\nobserved_counts &lt;- c(26, 36, 12, 14)\nexpected_counts &lt;- rep(88 / 4, 4)\nquarters &lt;- c(\"Q1\", \"Q2\", \"Q3\", \"Q4\")\n\ndata_plot &lt;- data.frame(\n  Quarter = rep(quarters, 2),\n  Count = c(observed_counts, expected_counts),\n  Type = rep(c(\"Observed\", \"Expected\"), each = 4)\n)\n\n#Plot the bar char\nggplot(data_plot, aes(x = Quarter, y = Count, fill = Type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Observed vs. Expected Player Birth Distribution\", \n       x = \"Birth Quarter\", \n       y = \"Number of Players\") +\n  scale_fill_manual(values=c(\"orange\",\"skyblue\"),\n                    labels=c(\"Expected\",\"Observed\")) +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nOnce again, the differences are very obvious from a visual standpoint, but no calculations have been made yet. To fully understand the significance of these values, we must perform statistical inference.\nUnder \\(H_0\\), each quarter should have a mean and standard deviation of:\n\\[\\mu = n \\times p = 88 \\times 0.25 = 22\\]\n\\[\\sigma = \\sqrt{\\mu \\times (1-p)} = \\sqrt{22 \\times 0.75} \\approx 4.06\\]\nThe Z-score for each quarter was calculated using the following equation, where X is the observed value for each quarter:\n\\[Z = \\frac{X - \\mu}{\\sigma}\\] The Z-scores for each quarter of our data were as follows:\n\\(\\bullet\\) Quarter 1: \\(Z_1 \\approx 0.99\\)\n\\(\\bullet\\) Quarter 2: \\(Z_2 \\approx 3.45\\)\n\\(\\bullet\\) Quarter 3: \\(Z_3 \\approx -2.46\\)\n\\(\\bullet\\) Quarter 4: \\(Z_4 \\approx -1.97\\)\nQuarter 2 immediately sticks out, with a Z-score greater than 3, but we’re looking at all four quarters, so we want a single value:\n\\[\\sum Z^2 = (0.99)^2 + (3.45)^2 + (-2.46)^2 + (-1.97)^2 = 22.81\\]\nThis value, 22.81, will be the observed statistic for our data. Right now, we do not know the significance of this value because we have nothing to compare it to. In order to generate enough data under the null-hypothesis to compare our observed statistic too, we simulated 1,000 identical data sets (88 players) with an equal probability of an athlete being born in each quarter. For each simulation, the Z-scores were computed for each quarter, and the sum of the squared Z-scores were calculated. Our final simulated data set contained 1,000 values, enough to form a distribution under \\(H_0\\).\nThe histogram below displays the distribution of the sums of the squared Z-scores from the simulations, with the red line marking our observed statistic:\n\n\nShow the code\n# Histogram of simulated sum of squared Z-scores\nggplot(sim_summary, aes(x = sum_z_squared)) +\n  geom_histogram(binwidth = 1, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = real_sum_z_sq, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Simulated Distribution of Sum of Squared Z-Scores\", \n       x = \"Sum of Squared Z-Scores\", \n       y = \"Count\") +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nOne important thing to note is that the distribution is noticeably right-skewed. This is a result of squaring our Z-scores. When Z-scores are squared, it removes all negative values, setting a floor at zero. The floor effect then causes a right-skew which is then amplified due to the fact that squaring values emphasizes differences.\nOur final step is to find a p-value for our data set, which is the probability of seeing our observed statistic or greater under the null-hypothesis. If \\(p &lt; 0.05\\) we will reject \\(H_0\\). Because the distribution of the sums of squared Z-scores is not normal, we cannot calculate the p-value using methods for a normal distribution. Instead, the following calculation was used:\n\\[p = \\frac{\\#\\text{ of simulations where} \\sum Z^2 \\ge 22.81}{\\text{Total Simulations}} = \\frac{1}{1000} = 0.001\\]\nWith a p-value of 0.001, this means that the probability of observing a sum of squared Z-scores of 22.81 or greater under the null-hypothesis is 0.1%, which is extremely low. Because \\(0.001 &lt; 0.05\\), we reject \\(H_0\\), with enough evidence to suggest that the distribution of birthdays for Canadian athletes in the NHL is not uniform.\n\n\nSummary\nThe goal of this project was to analyze the distribution of births among Canadian NHL players, following Malcom Gladwell’s claim that athletes born earlier in the year are more likely to become professional hockey players. Utilizing a sample of Canadian NHL players with a last name beginning with “L”, we were able to use simulations to test whether or not certain quarters of the year had an over-representation of births than others, comparing the data to simulated values where births were evenly distributed.\nAfter performing a hypothesis test, we concluded that our data significantly deviated from the simulated data, where we only saw a value greater than our observed value once out of 1,000 simulations (\\(p = 0.001\\)). Though this does not tell us specifically that those born earlier in the year are more likely to become professional hockey players, it heavily suggests that there is not an equal distribution of birthdays across Canadian NHL players. Applying this information to our specific example, where there were more births in the first half of the year than the second half of the year, we can conclude that individuals born earlier in the year are likely over-represented, supporting Malcom Gladwell’s claim. As stated in the introduction, this is likely a combination of various factors stemming from Canada’s age cutoff for junior level hockey leagues.\nThough our findings appear very strong, it is important to consider the limitations of this project. Because our data set only included athletes with last names beginning with a specific letter, it was not a random sample. Additionally, because only NHL players were included, there is no way to take into account all of the Canadian hockey players who never made it to the professional level. Improving our data to account for these factors could have a significant impact on our findings, allowing us to work with a greater number of both professional and developmental level hockey players.\nThere are various other ways this project can be expanded in the future. One simple way to gather more detailed results is to increase the number of simulations from 1,000 to 10,000. This will lead to a more accurate p-value, especially because we found that our observed data is very unlikely under a uniform distribution of births. With such a low probability, it is completely possible to compute a p-value of 0 with only 1,000 trials. Additionally, we can repeat this using players with last names beginning with different letters and include data prior to 1976 to see if we observe similar results. Another way to expand on this project would be investigating the ages at which athletes born earlier in the year begin to pull ahead, examining data from each year of junior level hockey in Canada. Finally, it would interesting to compare Canadian data to similar data sets from other parts of the world, adjusting to reflect the different age cutoffs for each country.\nOverall, while the time of year that an athlete is born may have some effect their success as they develop, it is important to consider how other external factors also promote professional opportunities, such as a player’s access to sufficient training and socioeconomic background."
  },
  {
    "objectID": "taper.html",
    "href": "taper.html",
    "title": "Thomas Matheis",
    "section": "",
    "text": "Web scraping, data cleaning/vizualization, and linear model used for this app to be added to this site soon"
  },
  {
    "objectID": "starbucks.html",
    "href": "starbucks.html",
    "title": "Starbucks Beverages",
    "section": "",
    "text": "This is the data set from Starbucks’ official 2021 nutritional information. Steamed milk data is omitted from this data set. The visualization displays the relationship between the amount of sugar in a beverage and its calories. The color is organized by type of milk. It can be seen that drinks with more sugar typically have a higher calorie count.\n\n\nShow the code\nlibrary(tidyverse)\nstarbucks &lt;- readr::read_csv(\"starbucks.csv\")\nggplot(starbucks, aes(x = calories, y = sugar_g)) +\n  geom_point(aes(color = milk)) +\n  geom_smooth(color = \"red\", method = \"gam\", formula = y ~ s(x, bs = \"cs\")) +\n  labs(\n    x = \"Calories (KCal)\",\n    y = \"Sugar (g)\",\n    title = \"Calories vs Sugar in Starbucks Drinks\",\n    color = \"Type of Milk:\\n0 - none\\n1 - nonfat\\n2 - 2%\\n3 - soy\\n4 - coconut\\n5 - whole\"\n  ) + theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nThe TidyTuesday data can be found at: https://github.com/rfordatascience/tidytuesday/tree/main/data/2021/2021-12-21.\nThe current nutritional information, from the official Starbucks website, can be found at: https://www.starbucks.ie/sites/starbucks-ie-pwa/files/2025-01/Winter%20Beverage%20Nutritionals%20.pdf"
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "Poorly Anonymized NYC Taxi Data",
    "section": "",
    "text": "Background\nIn 2014, New York City released a large dataset containing the details of over 173 million taxi trips. The decision to release the dataset followed a Freedom of Information request submitted by Chris Wong, an open data activist. This dataset included pick-up and drop-off locations, trip times, fares, and “anonymized” driver license numbers. However, Ars Technica later reported that the anonymization was incomplete, making it surprisingly easy to mathematically reverse-engineer and uncover individual drivers’ identities in just a few hours (Goodin 2014). Meanwhile, The Guardian warned that such revelations could compromise not just the drivers’ privacy, but high-profile passengers as well (Hern 2014). This situation highlights a significant topic of data science ethics. On the one hand, open data can be incredibly beneficial for urban planning, traffic analysis, and academic research, which may have been Chris Wong’s original intention. On the other hand, the poor anonymization of the data puts personal information at risk. As details like trip routes and tips suddenly became exposed to the community, drivers and their passengers had to worry about being identified and facing public scrutiny. This dilemma highlights how the power to collect and share data can inadvertently harm the very people it is meant to benefit.\n\n\nData Collection and Consent\nIn data science, data collection refers to gathering large amounts of information to be used for analysis. This commonly includes people, which introduces the problem that those whose data is being collected consent to it or even know about it. In this example, the New York City Taxi and Limousine Commission (TLC) legally collected taxi trip data for regulatory purposes, so there was no violation in the initial data gathering. This brings up the differences between legally-collected data and ethically-collected data. For example, many passengers and potentially even drivers may not have even known that data was being collected on them during every trip, which raises consent and privacy issues despite the information being collected lawfully. While the TLC did comply with the Freedom of Information request, it’s unclear if drivers were ever fully informed that details, like how much they earned and where they drove, were even a part of the dataset being released. Additionally, Ars Technica points out the existing privacy concerns revolving around the usage of GPS to track taxi driver’s trips and fares. (Goodin 2014) In this sense, the power dynamics heavily favor the TLC, leaving their drivers, and especially passengers, with little say over how their information is used.\n\n\nData Anonymization\nThe practice of removing personal identifiers from a dataset is known as data anonymization, and it is used to prevent individuals from being linked to any data that may have been collected about them. It becomes a major issue when anonymization techniques are weak and it becomes easy to identify people by cross-referencing with other datasets. As mentioned earlier, though the dataset was presented as “anonymized,” Vijay Pandurangan, a software developer, soon discovered that the same algorithm used to hash driver IDs could be used to reverse engineer and identify every medallion and license number in the span of a few hours (Hern 2014). This meant anyone interested could decode the hashed data and cross-reference it with TLC resources to match medallions to specific drivers. The Guardian warned that even passengers’ identities could be inferred with enough cross-referencing, such as matching time and location details to public events (Hern 2014). In this situation, if an individual saw a celebrity entering a taxi at a specific time and place, they could cross-reference the information to find the celebrity’s destination. New York City officials failed to protect their taxi driver’s privacy, with Ars Technica emphasizing that there were various other ways to successfully anonymize the data, for example, assigning “a random number to each hack license number and medallion number and use the substitute numbers throughout the disclosure” (Goodin 2014). This lack of anonymization shows how crucial it is to implement efficient privacy measures, especially when releasing data regarding people’s daily lives and routines.\n\n\nPermission for Using the Data\nThis was touched on in the last paragraph, but in general, permission to use data determines who can collect, access, and distribute said data. A major concern is determining if their is are ethical standards to consider even if one has a legal right to distribute data. In this scenario, The Freedom of Information Law (FOIL) required New York City officials to release some version of the requested data (Hern 2014). However, data science ethics suggest that an organization should go beyond minimum legal requirements and proactively protect individual privacy. The real question is whether the TLC even considered safer methods, such as providing less detailed data or seeking better encryption techniques, before making the dataset public (Goodin 2014). By not doing so, the agency unintentionally enabled widespread privacy invasions, effectively granting permission for others to dig into drivers’ details, which was likely never the original intent.\n\n\nUnintended Uses of the Data\nOnce data is made public, it can be used in ways the original collectors never anticipated. For example, in 2016 census data was used to create a function that predicted an individual’s race based on their last name and address, which employers could then use to discriminate against those who apply for jobs. In this case, the de-anonymized taxi data made it easy to identify where taxi drivers or passengers lived, and even how much money they made/tipped, information that could be used to easily target an individual. While some of the uses might be considered intriguing or even beneficial for academic research, many can be seen as a complete breach of privacy. As The Guardian stated, “anonymized” data can quickly become weaponized in the wrong hands, casting a dark light on how easily open data can turn into targeted surveillance (Hern 2014). This highlights how crucial it is to carefully consider the ethics of a situation to ensure the privacy and safety of the involved parties.\n\n\nCitations\nGoodin, Dan. 2014. “Poorly Anonymized Logs Reveal NYC Cab Drivers’ Detailed Whereabouts.” Ars Technica, June 26. https://arstechnica.com/tech-policy/2014/06/poorly-anonymized-logs-reveal-nyc-cab-drivers-detailed-whereabouts/.\nHern, Alex. 2014. “New York Taxi Details Whizz Around after ‘Anonymised’ Data Release.” The Guardian, June 27. https://www.theguardian.com/technology/2014/jun/27/new-york-taxi-details-anonymised-data-researchers-warn."
  },
  {
    "objectID": "policing.html",
    "href": "policing.html",
    "title": "Analyzing United States Policing Data",
    "section": "",
    "text": "Every Day, police officers throughout the United States make thousands of traffic stops, indirectly compiling millions of pieces of data over the courses of decades. The Stanford Open Policing Project has 88 data tables, which consist of 42 states, various city police departments, and state patrol records. The data ranges from 1999 to 2020, depending on the table. In this brief analysis, we will look at data from Los Angeles, Chicago, and California State Patrol, gathering information regarding demographics, the violation committed, and frequency of traffic stops.\nFirst, we will look at the demographic distribution over time for traffic stops conducted in the city of Los Angeles, California. While the data set includes information from December of 2009 to June of 2018, the range 2010 - 2017 was used to include all full years of data.\n\nSELECT raw_descent_description AS race,\n       count(*) AS race_count,\n       YEAR(date) AS year\nFROM ca_los_angeles_2020_04_01\nGROUP BY race, year\nHAVING year BETWEEN 2010 and 2017;\n\n\n\nShow the code\nlibrary(bit64)\nlibrary(scales)\n\nrace_table &lt;- race_table |&gt;\n  mutate(across(where(bit64::is.integer64), as.integer))    #Converting to acceptable format\n\nggplot(race_table, aes(x = year, y = race_count, color = race)) +\n  geom_line() +\n  scale_y_continuous(\n    labels  = comma_format()\n  ) +\n  labs(\n    title = \"Traffic Stops in Los Angeles by Race\",\n    x = \"Year\",\n    y = \"Number of Stops\",\n    subtitle = \"2010 - 2017\",\n    color = \"Race\"\n  ) +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nFrom 2010 to 2017, Hispanic individuals were stopped by police more frequently than any other race, with Black and White individuals the next most frequent. Races marked as Asian, American Indian, and other were all stopped relatively infrequently. While some people may immediately conclude that police officers in Los Angeles are more likely to stop people of Hispanic descent, it is important to take into consideration the demographic composition of the city itself. The United States Census Bureau lists that Hispanic or Latino individuals make up about 48.6% of the population, more than any other race. The same report lists that white people make up about 25.3% of the population, while those of Black descent make up about 9.0% of the population, both much lower than 48.6%.\nNext, we will investigate common traffic violations in Chicago, Illinois. There are dozens of possible violations, so only those with 40,000 or more occurrences were taken into account, giving us the top ten most common violations.\n\nSELECT violation AS Violation,\n       count(*) AS Count\nFROM il_chicago_2023_01_26\nGROUP BY Violation\nORDER BY Count DESC\nLIMIT 10;\n\n\n\nShow the code\nlibrary(gt)\nviolation_table |&gt;\n  gt() |&gt;\n  tab_header(title = md(\"Top 10 Traffic Violations in Chicago\"),\n             subtitle = md(\"Dec 2011 - May 2020\"))\n\n\n\n\n\n\n\n\nTop 10 Traffic Violations in Chicago\n\n\nDec 2011 - May 2020\n\n\nViolation\nCount\n\n\n\n\nHEADLIGHT TWO REQUIRED-MOTOR VEHICLE\n280628\n\n\nSTOP AT STOP SIGN\n248009\n\n\nLIGHT, TAIL LIGHTS REQUIRED\n110740\n\n\nDRIVING ON SUSPENDED LICENSE\n90483\n\n\nDISPLAY ST REG-FRONT/REAR\n90143\n\n\nDRIVING WHILE USING CELLULAR PHONE PROHIBITED\n67281\n\n\nDISOBEY RED CIRCULAR STEADY SIGNAL STOP\n64055\n\n\nREGISTRATION PLATES\n58338\n\n\nNO VALID REGISTRATION\n51230\n\n\nDISPLAY ST REG-REAR MOTRCYCL/TRLR/SEMI-TRLR\n49153\n\n\n\n\n\n\n\nFailing to have two functional headlights and failing to stop at a stop sign appear to be the two most common traffic violations in Chicago, with over 100,000 more occurrences than the third most common violation, which is failing to have two working tail lights. Four common violations all relate to registration: failure to display registration, no valid registration, no registration plates, and failure to display registration, this time for motorcycles and trailers. Some other common ones are driving on a suspended license and driving while using a cellphone.\nLast, we can add up the numbers of stops for each day of the month to see whether or not the California State Patrol tends to conduct more traffic stops at the beginning of the month, end of the month, or somewhere in the middle. Only 30 days were used, instead of 31, due to every month having at least 30 days. February was excluded due to its odd nature of only having 28 days.\n\nSELECT EXTRACT(DAY FROM date) AS day,\n       count(*) AS num_stops\nFROM ca_statewide_2023_01_26\nWHERE EXTRACT(MONTH FROM date) != 2\nGROUP BY day\nHAVING day &lt;= 30;\n\n\n\nShow the code\ndate_table &lt;- date_table |&gt;\n  mutate(across(where(bit64::is.integer64), as.numeric))\n\nggplot(date_table, aes(x = day, y = num_stops)) +\n  geom_smooth(method = \"loess\", \n              span = .75,\n              formula = y ~ x,\n              se = FALSE,                     \n              colour = \"lightblue\") +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"darkblue\") +\n  labs(\n    x = \"Day of the Month\",\n    y = \"Number of Stops\",\n    title = \"Number of Traffic Stops Each Day of the Month in California\",\n    subtitle = \"Jun 2009 - Jun 2016\"\n  ) +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nThere appears to be a slight tendency to conduct more traffic stops during the first few days of the month, with a steep decline during the last few days of the month, mostly the 30th. The light blue regression line indicates a slight inverse relationship between the day of the month and number of stops. While the differences are not huge, the small trend could have an explanation. For example, if quotas happen to exist within an agency, officers may be inclined to complete these quotas as soon as possible, slowly easing off once they have reached it.\nOverall, data gathered from traffic stop reports has the potential to reveal extremely interesting trends. We were able to easily examine the demographic composition of Los Angeles traffic stops, comparing them to the actual demographics of the city. We found that Hispanic individuals get stopped at a more frequent rate than other races, though they make up the majority of the overall population. In Chicago, the most common traffic violations were not having two working head lights and failing to stop at a stop sign, neither of which were very surprising. What was interesting was the violation that ranked fourth in frequency, driving with a suspended license. If almost 100,000 people were pulled over for not having a valid license, one can only imagine the number of people who get away with it and are driving every day. Finally, we discovered that, though small, there is some correlation between the day of the month and the frequency of traffic stops conducted. It was observed that it may be more likely to get pulled over during the first few days of the month compared to the end of the month, though the difference in frequency was not huge.\nSources:\nThe Los Angeles Census data can be found at: https://www.census.gov/quickfacts/fact/table/losangelescountycalifornia/RHI725223#qf-headnote-b\nThe policing database is a compilation of the Standford Open Policing Project, found at https://openpolicing.stanford.edu, and published in Pierson et al. (2020).\nReferences:\nPierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10."
  },
  {
    "objectID": "presentation.html#where-have-i-used-data-science",
    "href": "presentation.html#where-have-i-used-data-science",
    "title": "How I Have Used Data Science",
    "section": "Where Have I Used Data Science?",
    "text": "Where Have I Used Data Science?\nI was able to utilize skills learned in this class in primarily two places this semester:\n\\(\\bullet\\) Introduction to Statistics, Math 58 with Professor Chandler\n\\(\\bullet\\) The Student Life Newspaper, on the data team"
  },
  {
    "objectID": "presentation.html#what-parts-of-data-science-did-i-use",
    "href": "presentation.html#what-parts-of-data-science-did-i-use",
    "title": "How I Have Used Data Science",
    "section": "What parts of Data Science did I use?",
    "text": "What parts of Data Science did I use?\nSo far, the aspects of data science that I have found most useful include:\n\\(\\bullet\\) Data visualization with ggplot\n\\(\\bullet\\) Using Tidyverse verbs to organize and clean data\n\\(\\bullet\\) Permutation/randomization tests to simulate a probability\n\\(\\bullet\\) Web scraping"
  },
  {
    "objectID": "presentation.html#analyzing-relative-age-effect-for-canadian-nhl-players",
    "href": "presentation.html#analyzing-relative-age-effect-for-canadian-nhl-players",
    "title": "How I Have Used Data Science",
    "section": "Analyzing Relative Age Effect for Canadian NHL Players",
    "text": "Analyzing Relative Age Effect for Canadian NHL Players\n\n#Utilizing a given data-set \"Bdays.recent\"\n\nggplot(Bdays.recent, aes(x = year, y = NumDays)) +\n  geom_point(color = \"black\") +\n  geom_hline(yintercept = 182.5, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Year\",\n    y = \"Day of the Year\",\n    title = \"Birthdays of Canadian NHL Players\",\n    subtitle = \"n = 88\"\n  ) + theme_minimal(base_family = \"Palatino\")"
  },
  {
    "objectID": "presentation.html#analyzing-average-lag-time-between-local-and-non-local-runners",
    "href": "presentation.html#analyzing-average-lag-time-between-local-and-non-local-runners",
    "title": "How I Have Used Data Science",
    "section": "Analyzing Average Lag-Time Between Local and Non-Local Runners",
    "text": "Analyzing Average Lag-Time Between Local and Non-Local Runners\n\n#Utilizing a given data set \"TMR.mini\"\n\nggplot(TMR.mini, aes(x=DMV, y=lag, fill=DMV)) +\n  geom_boxplot() +\n  labs(title=\"Comparison of Lag Times by Runner Origin\"\n       x=\"Local?\",\n       y=\"Lag (seconds)\") +\n  scale_fill_manual(values=c(\"orange\",\"skyblue\"),\n                    labels=c(\"Non-local\",\"Local\")) +\n  theme_minimal(base_family = \"Palatino\")"
  },
  {
    "objectID": "presentation.html#pomona-pitzer-athletics-spending",
    "href": "presentation.html#pomona-pitzer-athletics-spending",
    "title": "How I Have Used Data Science",
    "section": "Pomona-Pitzer Athletics Spending",
    "text": "Pomona-Pitzer Athletics Spending\n\nppeada1 &lt;- ppeada |&gt; \n  filter(sport != \"Baseball\", sport != \"Football\", sport != \"Softball\", sport != \"Volleyball\", sport != \"Lacrosse\")\nppeada2 &lt;- ppeada23 |&gt; \n  filter(sport != \"Baseball\", sport != \"Football\", sport != \"Softball\", sport != \"Volleyball\", sport != \"Lacrosse\")\n\nggplot(ppeada2, aes(x = sport, y = expenses, fill = sex)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  scale_fill_manual(\n    values = c(\n      \"M\"   = \"#0057b8\",   \n      \"F\" = \"#f7941d\"    \n    ),\n    name = \"Team\"\n  ) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    x = \"\", y = \"Proportion of Funding\",\n    title = \"Proportions of Funding Between Men's and Women's Teams by Sport\",\n    subtitle = \"2022-2023\"\n  ) +\n  theme_minimal(base_family = \"Palatino\")"
  },
  {
    "objectID": "presentation.html#pomona-pitzer-athletics-spending-1",
    "href": "presentation.html#pomona-pitzer-athletics-spending-1",
    "title": "How I Have Used Data Science",
    "section": "Pomona-Pitzer Athletics Spending",
    "text": "Pomona-Pitzer Athletics Spending\n\nggplot(ppeada1, aes(x = sport, y = expenses, fill = sex)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  scale_fill_manual(\n    values = c(\n      \"M\"   = \"#0057b8\",   \n      \"F\" = \"#f7941d\"   \n    ),\n    name = \"Team\"\n  ) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  labs(\n    x = \"\", y = \"Proportion of Funding\",\n    title = \"Proportions of Funding Between Men's and Women's Teams by Sport\",\n    subtitle = \"2023-2024\"\n  ) +\n  theme_minimal(base_family = \"Palatino\")"
  },
  {
    "objectID": "presentation.html#fall-2025-pre-registration",
    "href": "presentation.html#fall-2025-pre-registration",
    "title": "How I Have Used Data Science",
    "section": "Fall 2025 Pre-Registration",
    "text": "Fall 2025 Pre-Registration\n\n#Using data collected from Hyperschedule every 15 minutes during registration\n\nggplot(num_closed, aes(x = DateTime, y = closed)) +\n  geom_line(color = \"blue\", linewidth = 1.7) +\n  geom_vline(xintercept = as.POSIXct(\"2025-04-22 08:00:00\", tz = \"America/Los_Angeles\"), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\",\n           x = as.POSIXct(\"2025-04-22 9:00:00\",\n                          tz = \"America/Los_Angeles\"),\n           y = 700,            \n           label = \"Start of Senior \\nRegistration\", hjust = 0, size = 3.5, family = \"Palatino\") +\n  geom_vline(xintercept = as.POSIXct(\"2025-04-23 08:00:00\", tz = \"America/Los_Angeles\"), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\",\n           x = as.POSIXct(\"2025-04-23 9:00:00\",\n                          tz = \"America/Los_Angeles\"),\n           y = 700,            \n           label = \"Start of Sophomore \\nRegistration\", hjust = 0, size = 3.5, family = \"Palatino\") +\n  geom_vline(xintercept = as.POSIXct(\"2025-04-24 08:00:00\", tz = \"America/Los_Angeles\"), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\",\n           x = as.POSIXct(\"2025-04-24 9:00:00\",\n                          tz = \"America/Los_Angeles\"),\n           y = 700,            \n           label = \"Start of Freshmen \\nRegistration\", hjust = 0, size = 3.5, family = \"Palatino\") +\n  scale_y_continuous(limits = c(0, 750),\n                     breaks  = seq(0, 750, by = 100)) +\n  scale_x_datetime(\n    breaks = seq(from   = start,\n                 to     = max(num_closed$DateTime),   # or a hard date\n                 by     = \"8 hours\"),\n    timezone     = \"America/Los_Angeles\",   # &lt;-- converts tick labels\n    date_labels  = \"%b %d\\n%I:%M %p\"           # e.g. \"Apr 23\\n01:00\"\n  ) +\n  labs(\n    x = \"\",\n    y = \"Number of Courses\",\n    title = \"Courses Closed During Fall 2025 Pre-Registration\"\n  ) +\n  theme_minimal(base_family = \"Palatino\") +\n  theme(plot.title = element_text(size = 18))"
  },
  {
    "objectID": "presentation.html#current-project-scraping-swimcloud.com",
    "href": "presentation.html#current-project-scraping-swimcloud.com",
    "title": "How I Have Used Data Science",
    "section": "Current Project: Scraping Swimcloud.com",
    "text": "Current Project: Scraping Swimcloud.com\n\nswimmers_2025_M &lt;- function(page) {\n  url &lt;- paste0(\"https://www.swimcloud.com/recruiting/rankings/2025/M/1/?page=\", page)\n  page &lt;- read_html(url)\n  \n  ranking &lt;- page |&gt;\n    html_elements(\".u-pr0\") |&gt;\n    html_text() |&gt;\n    as.numeric()\n\n  power_index &lt;- page |&gt;\n    html_elements(\"td.u-text-end\") |&gt;\n    html_text() |&gt;\n    as.numeric()\n\n  state &lt;- page |&gt;\n    html_elements(\".u-text-small\") |&gt;\n    html_text() |&gt;\n    str_extract(\"[A-Z]{2}$\")\n\n  swimmers &lt;- tibble(\n    ranking = ranking,\n    power_index = power_index,\n    state = state,\n    sex = \"M\"\n  )\n}\n\npages &lt;- 1:537\ntop_swimmers_2025_M &lt;- map_dfr(pages, swimmers_2025_M) |&gt;\n  write.csv(\"top_swimmers_2025_M.csv\")"
  },
  {
    "objectID": "presentation.html#thank-you",
    "href": "presentation.html#thank-you",
    "title": "How I Have Used Data Science",
    "section": "Thank you!",
    "text": "Thank you!\n```"
  },
  {
    "objectID": "spotify.html",
    "href": "spotify.html",
    "title": "Spotify Wrapped",
    "section": "",
    "text": "After viewing my 2024 Spotify Wrapped (pictured above), I questioned the validity of the results that were displayed. Was Drake really one of my top artists? Did I really listen to Dominic Fike more than Twenty One Pilots? Using Spotify’s “Data Request” feature, I was able to receive copies of my streaming history from November 4th, 2023 to November 4th, 2024.\nFirst, I merged the set of three JSON files I received, and converted them into a single csv file to make it easier to work with, reading the csv into a data table:\n\n\nShow the code\ndf1 &lt;- fromJSON(\"StreamingHistory_music_0.json\")                    #Importing the .JSON files\ndf2 &lt;- fromJSON(\"StreamingHistory_music_1.json\")\ndf3 &lt;- fromJSON(\"StreamingHistory_music_2.json\")\n\nmerged_df &lt;- bind_rows(df1, df2, df3)\n\nwrite.csv(merged_df, \"spotify_data.csv\", row.names = FALSE)         #Writing as a single .csv file \nspotify_csv &lt;- read_csv(\"spotify_data.csv\")\nspotify_data &lt;- spotify_csv |&gt; mutate(endTime = as.Date(endTime))\nhead(spotify_data, 5)\n\n\n# A tibble: 5 × 4\n  endTime    artistName        trackName      msPlayed\n  &lt;date&gt;     &lt;chr&gt;             &lt;chr&gt;             &lt;dbl&gt;\n1 2023-10-17 Bad Bunny         MONACO            69369\n2 2023-11-04 Twenty One Pilots Heavydirtysoul     2944\n3 2023-11-04 Twenty One Pilots Hometown            874\n4 2023-11-04 Twenty One Pilots Levitate            768\n5 2023-11-04 Twenty One Pilots Ride                917\n\n\nIt can be seen that the “artistsName” and “trackName” variables both contain character strings, which is what we’ll be working with. Just to simplify things, I converted the “endTime” variable from &lt;S3: POSIXct&gt; to &lt;date&gt;. The variable “msPlayed” contains &lt;dbl&gt; values which measure the time listened to a song measured in milliseconds.\nNow we can being working with the strings!\nOne observation I made in the dataset was that many songs have a feature artist, and therefore have “(feat. ‘artist name’)” in the title. We can clean the dataset by removing the features from the track names!\nFirst, let’s look at some examples of what this looks like, using str_detect:\n\n\nShow the code\nfeature_example &lt;- spotify_data |&gt;\n  filter(str_detect(trackName,\"\\\\(feat.*\\\\)\")) |&gt;    #Filters to show strings including \"feat.\"\n  select(artistName, trackName)\nhead(feature_example, 5)\n\n\n# A tibble: 5 × 2\n  artistName             trackName                                        \n  &lt;chr&gt;                  &lt;chr&gt;                                            \n1 Lil Uzi Vert           Neon Guts (feat. Pharrell Williams)              \n2 Metro Boomin           Space Cadet (feat. Gunna)                        \n3 Metro Boomin           Too Many Nights (feat. Don Toliver & with Future)\n4 Gunna                  P power (feat. Drake)                            \n5 A Boogie Wit da Hoodie Drowning (feat. Kodak Black)                     \n\n\nNow, using str_relpace_all to remove all features, and str_trim to remove all spaces after the string:\n\nspotify_data_nofeat &lt;- spotify_data |&gt;\n  mutate(trackName = str_replace_all(trackName,\"\\\\(feat.*\\\\)\", \"\")) |&gt;\n  mutate(trackName = str_trim(trackName))\n\nUsing the same five songs as before, we can now show how the features have been removed:\n\n\nShow the code\nfeature_example1 &lt;- spotify_data_nofeat |&gt;\n  filter(str_detect(trackName, \"Neon Guts|Space Cadet|Too Many Nights|P power|Drowning\")) |&gt;\n  select(artistName, trackName)   #Selecting the same example used before\nhead(feature_example1,5)\n\n\n# A tibble: 5 × 2\n  artistName             trackName      \n  &lt;chr&gt;                  &lt;chr&gt;          \n1 Lil Uzi Vert           Neon Guts      \n2 Metro Boomin           Space Cadet    \n3 Metro Boomin           Too Many Nights\n4 Gunna                  P power        \n5 A Boogie Wit da Hoodie Drowning       \n\n\nBoom! No features! Let’s look at some rows in the data and see if it looks better:\n\n\nShow the code\nfeature_example2 &lt;- spotify_data_nofeat |&gt;\n  select(artistName, trackName)\nfeature_example2[41:47,]          #A random selection of data\n\n\n# A tibble: 7 × 2\n  artistName             trackName                                              \n  &lt;chr&gt;                  &lt;chr&gt;                                                  \n1 A Boogie Wit da Hoodie Drowning                                               \n2 Metro Boomin           Superhero (Heroes & Villains) [with Future & Chris Bro…\n3 Chief Keef             Love Sosa                                              \n4 Drake                  Rich Flex                                              \n5 Future                 Solo                                                   \n6 Metro Boomin           Trance (with Travis Scott & Young Thug)                \n7 Mac Miller             Ayye                                                   \n\n\nUh oh! We didn’t account for features that use “with” instead of “feat.” Also, we can see that some songs use brackets while others use parenthesis. We can use lookarounds and some more regular expressions to account for the variations of “with” that song titles use:\n\nspotify_data_nofeat &lt;- spotify_data_nofeat |&gt;\n  mutate(trackName = str_replace_all(trackName,\"(?&lt;=\\\\s)(\\\\(.*?\\\\)|\\\\[.*?\\\\]|\\\\swith\\\\s)(.*)\", \"\")) |&gt;\n  mutate(trackName = str_trim(trackName))\n\nThe escapes make it look a little messy, but this uses a positive lookbehind to check for a space before matching any text in parenthesis, brackets, or simply “with” with any spaces around it. We replace all of the matches to this pattern with an empty space. Here’s our example again, displaying the updated results:\n\n\nShow the code\nfeature_example2 &lt;- spotify_data_nofeat |&gt;\n  select(artistName, trackName)\nfeature_example2[41:47,]        #Same example as before\n\n\n# A tibble: 7 × 2\n  artistName             trackName\n  &lt;chr&gt;                  &lt;chr&gt;    \n1 A Boogie Wit da Hoodie Drowning \n2 Metro Boomin           Superhero\n3 Chief Keef             Love Sosa\n4 Drake                  Rich Flex\n5 Future                 Solo     \n6 Metro Boomin           Trance   \n7 Mac Miller             Ayye     \n\n\nThis looks much cleaner now.\nNow that we have a clean data frame containing the artist name, song name, date, and amount of time listened too, we can make some graphs!\nFirst, I want to look at my top five artists by listening time. To do this, we need to add up the total play time each artist received:\n\nmsPlayed_artist &lt;- spotify_data_nofeat |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_msPlayed = sum(msPlayed)) |&gt;\n  arrange(desc(total_msPlayed)) |&gt;\n  head(5)\n\nTime to graph:\n\n\nShow the code\nggplot(msPlayed_artist, aes(x = fct_reorder(artistName, total_msPlayed), y = total_msPlayed, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Listening Time (ms)\",\n    title = \"My Top Five Spotify Artists by Listening Time\",\n    fill = \"Artist\"\n  ) + \n  coord_flip() +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nWell that’s odd, it looks like my order doesn’t match with what Spotify told me. Twenty One Pilots has significantly more total listening time than Dominic Fike, yet Dominic Fike appears first on the official list.\nWhat if we look at total songs played instead of listening time:\n\ntotal_songs_artist &lt;- spotify_data_nofeat |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_songs = n()) |&gt;\n  arrange(desc(total_songs)) |&gt;\n  head(5)\n\nOnce again graphing:\n\n\nShow the code\nggplot(total_songs_artist, aes(x = fct_reorder(artistName, total_songs), y = total_songs, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Songs Played\",\n    title = \"My Top Five Spotify Artists by Total Songs Played\",\n    fill = \"Artist\"\n  ) + \n  coord_flip() +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nWell, at least this tells us that something isn’t quite right with how Spotify determines a user’s top artists. Our top 5 artists measured by total songs played is in the same order as when we measure by total listening time, however this time Twenty One Pilots and Dominic Fike are much closer. This tells me that Drake for sure belonged on my Spotify Wrapped, as he ranked 3rd in total songs played and total listening time. I also confirmed my suspicion that I listened to more Twenty One Pilots than any other artist, especially when looking at listening time. One reason for the discrepancy could be the time frame that Spotify uses. My data begins in November of 2023 and ends in November of 2024. It could be possible that Spotify uses data beginning on January 1st of each year. We can use only the songs from January 1st and onwards to see if it significantly changes our results.\nRepeating the process for listening time:\n\n\nShow the code\nspotify_2024_only1 &lt;- spotify_data_nofeat |&gt;\n  filter(endTime &gt;= \"2024-01-01\") |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_msPlayed = sum(msPlayed)) |&gt;\n  arrange(desc(total_msPlayed)) |&gt;\n  head(5)\n\nggplot(spotify_2024_only1, aes(x = fct_reorder(artistName, total_msPlayed), y = total_msPlayed, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Listening Time (ms)\",\n    title = \"My Top Five Spotify Artists by Listening Time for 2024\",\n    fill = \"Artist\"\n  ) + \n  coord_flip() +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nRepeating the process for total songs played:\n\n\nShow the code\nspotify_2024_only2 &lt;- spotify_data_nofeat |&gt;\n  filter(endTime &gt;= \"2024-01-01\") |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_songs = n()) |&gt;\n  arrange(desc(total_songs)) |&gt;\n  head(5)\n\nggplot(spotify_2024_only2, aes(x = fct_reorder(artistName, total_songs), y = total_songs, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Songs Played\",\n    title = \"My Top Five Spotify Artists by Total Songs Played for 2024\",\n    fill = \"Artist\"\n  ) + \n  coord_flip() +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nThis data is closer to the official Spotify Wrapped, though still not quite right. When looking at total listening time for 2024, Don Toliver pushes his way up to third on the list, which is where he was officialy ranked. However, when looking at total songs played for 2024, the only time Dominic Fike has outranked Twenty One Pilots, Don Toliver falls places fifth by almost 500 songs.\nOverall, Spotify Wrapped does a good-enough job in the sense that it correctly identified my top artists artists for both total listening time and total songs played. However, the order that it ranked my top five artsits in doesn’t seem to quite line up with my streaming history data. However, as we found above, the time frame of the data can make a big difference in the rankings. My data contained history up until November 4th, and it is likely that Spotify Wrapped, which released on December 4th, utilized that extra month of streaming history that was not included in the files I received. This extra month of missing data could explain some of the differences in rankings I found.\nTo view the data:\nThe three individual .JSON files of my Spotify streaming history and the merged .csv file can be accessed on the public repository for this website!\nhttps://github.com/thomasmatheis2028/thomasmatheis2028.github.io"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thomas Matheis",
    "section": "",
    "text": "Hey! I’m Tommy, a current first year at Pomona College. I love math and data science, and I’m excited to build upon my current knowledge in those fields. Outside of the classroom, I am a diver on Pomona-Pitzer’s Swimming & Diving team. My hobbies include listening to indie music, going on long drives, and mountain biking."
  },
  {
    "objectID": "swimmers.html",
    "href": "swimmers.html",
    "title": "Age-Group Swimming",
    "section": "",
    "text": "Web Scraping:\nShow the code\nswimmers_2025_M &lt;- function(page) {\n  url &lt;- paste0(\"https://www.swimcloud.com/recruiting/rankings/2025/M/1/?page=\", page)\n  page &lt;- read_html(url)\n  \n  ranking &lt;- page |&gt;\n    html_elements(\".u-pr0\") |&gt;\n    html_text() |&gt;\n    as.numeric()\n\n  power_index &lt;- page |&gt;\n    html_elements(\"td.u-text-end\") |&gt;\n    html_text() |&gt;\n    as.numeric()\n\n  state &lt;- page |&gt;\n    html_elements(\".u-text-small\") |&gt;\n    html_text() |&gt;\n    str_extract(\"[A-Z]{2}$\")\n\n  swimmers &lt;- tibble(\n    ranking = ranking,\n    power_index = power_index,\n    state = state,\n    sex = \"M\"\n  )\n}\n\npages &lt;- 1:537\ntop_swimmers_2025_M &lt;- map_dfr(pages, swimmers_2025_M) |&gt;\n  write.csv(\"top_swimmers_2025_M.csv\")\n\nswimmers_2025_F &lt;- function(page) {\n  url &lt;- paste0(\"https://www.swimcloud.com/recruiting/rankings/2025/F/1/?page=\", page)\n  page &lt;- read_html(url)\n  \n  ranking &lt;- page |&gt;\n    html_elements(\".u-pr0\") |&gt;\n    html_text() |&gt;\n    as.numeric()\n\n  power_index &lt;- page |&gt;\n    html_elements(\"td.u-text-end\") |&gt;\n    html_text() |&gt;\n    as.numeric()\n\n  state &lt;- page |&gt;\n    html_elements(\".u-text-small\") |&gt;\n    html_text() |&gt;\n    str_extract(\"[A-Z]{2}$\")\n\n  swimmers &lt;- tibble(\n    ranking = ranking,\n    power_index = power_index,\n    state = state,\n    sex = \"F\"\n  )\n}\n\npages &lt;- 1:609\ntop_swimmers_2025_F &lt;- map_dfr(pages, swimmers_2025_F) |&gt;\n  write.csv(\"top_swimmers_2025_F.csv\")\nData Cleaning:\nShow the code\nswimmers_M &lt;- read.csv(\"top_swimmers_2025_M.csv\") |&gt;\n  select(-X) |&gt;\n  filter(ranking &lt;= 1000)\nswimmers_F &lt;- read.csv(\"top_swimmers_2025_F.csv\") |&gt;\n  select(-X) |&gt;\n  filter(ranking &lt;= 1000)\n\ntop_states_M &lt;- swimmers_M |&gt;\n  group_by(state) |&gt;\n  summarize(n = n()) |&gt;\n  arrange(desc(n))\n\ntop_states_F &lt;- swimmers_F |&gt;\n  group_by(state) |&gt;\n  summarize(n = n()) |&gt;\n  arrange(desc(n))\n\ntop_100_M &lt;- swimmers_M |&gt;\n  group_by(state) |&gt;\n  slice_min(order_by = power_index, n = 50, with_ties = FALSE) |&gt;\n  filter(n() == 50) |&gt;\n  ungroup()\n\ntop_100_F &lt;- swimmers_F |&gt;\n  group_by(state) |&gt;\n  slice_min(order_by = power_index, n = 50, with_ties = FALSE) |&gt;\n  filter(n() == 50) |&gt;\n  ungroup() |&gt;\n  filter(state != \"IL\") |&gt;\n  mutate(sex = as.character(\"F\"))"
  },
  {
    "objectID": "swimmers.html#introduction",
    "href": "swimmers.html#introduction",
    "title": "Age-Group Swimming",
    "section": "Introduction",
    "text": "Introduction\nIn the world of Junior Age Group Swimming, very few states have had as significant of an impact as California. Having been historically viewed as a talent powerhouse, California has consistently produced Olympians, national record holders, and some of the top college recruits every year. Despite the state’s long track record as an elite swimming superpower for those under the age of 18, the swimming world continues to evolve, with states such as Texas, Florida, and Virginia emerging as potential contenders for the “best” swimming state. Many people in the swimming world have begun to wonder if California is maintaining its dominance, or if other states have begun to catch up or even surpass it. The 2022 SwimSwam article, “Has American Age Group Swimming Power Shifted East?” highlights the recent debate that has emerged surrounding the Age Group Swimming scene in the United States. The author, long time swimmer and coach Michael Hamann, brings up the argument that while the sheer population of California results in the state having a higher quantity of top swimmers, if trends continue than East-coast states such as Virginia and North Carolina have a high chance of becoming the new hub of elite junior swimming. Hamann continues to state that according to USA Swimming’s own club rankings, “the top 5 teams from the 2021-22 short course season all hail from North Carolina, Virginia or the D.C. metro area,” reinforcing the idea that California may be losing its grip as a powerhouse.\nOn the other hand, one could also make the point that due to California’s size, their talent may be more spread out among different club teams, while top swimmers in smaller states may be more concentrated in fewer club teams. In another article, “Which State Had the Best High School Swimming During the 2022-2023 Season?” published by Swimming World Magazine, Bucknell University swimmer Avery Kuhn mentions that for the 2021-2022 high school season, “California had the largest total number of All-Americans, with Texas close behind,” even going further to reference the fact that for the following season, 2022-2023, California girls made up 25% of the top 20 200 medley relay times. So, despite the argument that swimming dominance may be heading towards the East coast, recent high school swimming results seem to keep California as the clear outlier, especially for women’s swimming.\nReturning to the question of whether or not California is still an age group swimming powerhouse, in this case, “powerhouse” being defined as a state which consistently produces a high volume of elite swimmers, this project will be investigating this year’s class of high school senior swimmers to determine how California relates to other states. Comparing California’s current top swimmers to those of other standout states will allow us to make a decision on whether or not California remains dominant, for both men and women’s swimming respectively. Section 2 of this project will detail the methods and reasoning behind the selection of the data, including surface-level visual summaries of the data. Section 3 will go through the statistical analysis utilized to obtain results, applying statistical inference to come to the relevant conclusions. Section 4 will present this conclusion, summarizing the results of the overall project and provide an insight of what future work on this topic may look like."
  },
  {
    "objectID": "swimmers.html#methods",
    "href": "swimmers.html#methods",
    "title": "Age-Group Swimming",
    "section": "Methods",
    "text": "Methods\nIn order to adequately explore our hypothesis regarding California’s dominance in age group swimming, we must gather and examine data, obtaining a sample that represents the greater population. In this case, we will be looking at high school swimmers that will be graduating in the Spring of 2025. The full data set included all men and women in this category, scraped from a public swimming database, swimcloud.com, amounting to over 50,000 swimmers. Both the male and female data sets included the ranking, state, and power index for each swimmer. To limit our data to a more manageable size, we first limited our data to the top 1,000 swimmers nationally for both men and women, focusing on those of elite performance only. These swimmers represent the top talent in the country and will likely be recruited to swim at the NCAA level. From there, to narrow down potential powerhouse states, we identified all of the states that had at least 50 men and 50 women in the top 1,000, and only looked at those top 50 athletes. This also ensured that the states included in the analysis had an equal and large enough sample. The end result consisted of six states: California, Texas, Florida, North Carolina, Pennsylvania, and Virginia.\nEvery swimmer in this data set is ranked by their aforementioned power index, a standard performance metric used in swim recruiting to represent the overall skill of the athlete. This number is calculated by comparing each swimmer’s five fastest events to the times of other high school swimmers of the same class. The power index ranges from 1.00 to 100.00, with 1.00 being the fastest (top swimmer or swimmers of the class) and 100.00 being the slowest. Having a standardized number to rank recruits allows college coaches to make quick comparisons when recruiting. The visual below displays the distribution of power index for each state included in this project, for both men and women:\n\n\nShow the code\ntop_100_MF &lt;- bind_rows(top_100_M, top_100_F)\n\nggplot(top_100_MF, aes(x=state, y=power_index, fill=sex)) +\n  geom_boxplot() +\n  labs(\n    x = \"State\",\n    y = \"Power Index\",\n    title = \"Comparison of Power Index by State\",\n    subtitle = \"Top 50 Swim Recruits per State\",\n    fill = \"Sex\"\n  ) +\n  scale_fill_manual(values=c(\"orange\",\"skyblue\"),\n                    labels=c(\"Female\",\"Male\")) +\n  facet_wrap(~ sex) +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nThere are some important visual observations to be made here. For example, on the women’s side, while every state except Florida appears to have some fast swimmers with a power index below 5, California’s highest power index appears to be at or lower than the medians of the other states. On the other hand, states appear to be much more even on the men’s side, though Texas appears to have a lower median power index than the other five states. Additionally, California once again tends to have the lowest maximum power index. However, it is unclear if these visual discrepancies are due to state-wide dominance or simply the variability of skill.\nIn order to investigate if California can still be considered an age group swimming powerhouse, which relies on if their swimmers are truly faster on average, we will perform two separate analysis of variance (ANOVA) tests, on the male sample and women sample respectively. Conducting an ANOVA test will help us conclude whether there are any statistically significant differences in the mean power indexes across all six states in the samples. This method is appropriate for this project because it compares the means of a numeric variable (the power index) across various categorical groups (the states). If a statistically significant difference is found, we will then conduct a Tukey Honest Significant Difference (HSD) test to determine the specific states that differed from California by observing the pairwise comparisons.\nIt is important to note that these are not a random samples of age group swimmers, but instead, as stated above, a carefully selected group of some of the top 2025 graduating seniors in the country. We completely disregarded swimmers from 44 states, along with the hundreds of thousands of swimmers in other grades. Despite these clear limitations, the samples represent the recruiting pool that hundreds of college coaches look at every year, along with the rest of the nation’s elite swim recruits. This project is not an attempt to generalize all swimmers in the country, but instead to identify the trends in top swimming performance among a few standout states. In that case, these two samples of male and female recruits contain enough data for us to draw relevant conclusions regarding the six selected states and how California compares to the other five."
  },
  {
    "objectID": "swimmers.html#data-analysis",
    "href": "swimmers.html#data-analysis",
    "title": "Age-Group Swimming",
    "section": "Data Analysis",
    "text": "Data Analysis\nBefore comparing power indexes between states, we first examined the overall distribution of the power index for both men and women. Looking at the chart below, it can be seen that the distributions for both sexes are left skewed, with peaks around 15-20. These trends are to be expected and can be explained by the fact that we have selected only the top elite swimmers and excluded slower swimmers. There are less swimmers with a sub-10 power index, leading to a concentration in power indexes between 10 and 30. This distribution also helps explain some of the trends seen in the residual plots later in the ANOVA testing.\n\n\nShow the code\nggplot(top_100_MF, aes(x = power_index, fill = sex)) +\n  geom_histogram(color = \"black\", bins = 13) +\n  facet_wrap(~ sex) +\n  labs(\n    x = \"Power Index\",\n    y = \"Density\",\n    title = \"Power Index Distribution Among Top States\",\n    subtitle = \"n = 50 swimmers per state\"\n  ) +\n  scale_fill_manual(values=c(\"orange\",\"skyblue\"),\n                    labels=c(\"Female\",\"Male\")) +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nOur goal in this project is to determine if California is significantly faster than the other top age group swimming states in the country, which can be measured by examining average power indexes amongst the top swimmers in each state. Once again, a lower average power index indicates faster swimmers, while a higher power index indicates slower swimmers. In order to test whether swimmer performance differs by state, we conducted an Analysis of Variance test separately for both men and women. Our null hypothesis and alternate hypothesis can be written as follows:\n\\[H_0: \\mu_{CA} = \\mu_{TX} = \\mu_{FL} = \\mu_{PA} = \\mu_{VA} = \\mu_{NC}\\]\n\\[H_A: \\text{not } H_0\\] While ANOVA tells us if any significant differences exist by giving us an F-statistic, where a value significantly greater than 1 tells us that at least one group mean differs from the rest, what we are really looking for is whether or not California’s swimmers are faster or slower than those of other states. To do this, we followed each ANOVA test with a Tukey Honest Significant Differences test to make pairwise comparisons between California.\nAfter conducting the two separate ANOVA tests for male and female age group swimmers, the resulting F-statistics were:\n\\(\\bullet\\ F_M \\approx 3.81\\)\n\\(\\bullet\\ F_F \\approx 13.31\\)\nBecause we know that \\(F \\approx 1\\) if the null is true and \\(F &gt; 1\\) for both men and women (much greater than 1 in the case of women), it indicates that a statistically significant difference does exist between states. Additionally, the corresponding p-values of the F-statistics were \\(p_M \\approx 0.002\\) and \\(p_F \\approx 0\\), indicating that we should reject our overall null hypothesis that all states have about an equal average power index. However, the next question we want to know is whether or not it is California that differs significantly. To figure this out, we then conducted the Tukey HSD tests on the two groups, only looking at comparisons involving California. The plot below displays the results for both men and women, and each horizontal line represents a 95% confidence interval for the mean difference between California and another state.\n\n\nShow the code\naov_men &lt;- aov(power_index ~ state, data = top_100_M)\n\ntukey_emm_m &lt;- emmeans(aov_men, pairwise ~ state, adjust = \"tukey\", infer = c(TRUE, TRUE))\ntukey_df_m &lt;- as.data.frame(tukey_emm_m$contrasts) |&gt;\n  filter(grepl(\"^CA\", contrast))\n\ntukey_men &lt;- ggplot(tukey_df_m, aes(x = contrast, y = estimate)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  coord_flip() +\n  labs(title = \"Tukey HSD Comparisons of Power Index by State\",\n       subtitle = \"Top 50 Male Swim Recruits per State\",\n       x = \"State Comparison\",\n       y = \"Estimated Mean Difference\") +\n  theme_minimal(base_family = \"Palatino\")\n\n\naov_women &lt;- aov(power_index ~ state, data = top_100_F)\n\ntukey_emm_f &lt;- emmeans(aov_women, pairwise ~ state, adjust = \"tukey\", infer = c(TRUE, TRUE))\ntukey_df_f &lt;- as.data.frame(tukey_emm_f$contrasts) |&gt;\n  filter(grepl(\"^CA\", contrast))\n\ntukey_women &lt;- ggplot(tukey_df_f, aes(x = contrast, y = estimate)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL), width = 0.2) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  coord_flip() +\n  labs(title = \"Tukey HSD Comparisons of Power Index by State\",\n       x = \"State Comparison\",\n       subtitle = \"Top 50 Female Swim Recruits per State\",\n       y = \"Estimated Mean Difference\") +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\n\n\nFor men, the results were fairly mixed. California had a lower (faster) mean power index than Virginia, Pennsylvania, and North Carolina, and a higher (slower) mean than Texas and Florida. However, the confidence intervals for all five comparisons all crossed 0, meaning that none of the differences found between California were significantly different and could have just occurred through chance. This means that the high F-statistic and resulting low p-value for men came from significant differences between other states, not involving California.\nOn the women’s side of things, the results were much more conclusive. California had a lower mean power index than all five other states, and the 95% confidence interval did not cross zero for any of the states. This indicates that the differences between California and the other states were significantly different, meaning that California’s top female swimmers are significantly faster than the top female swimmers from the other top states.\nAdditionally, we can look at the residual plots for both men and women to confirm the validity of the ANOVA tests. The 2x2 chart below displays some useful residual visualizations, with men on the top row and women on the bottom row:\n\n\n\n\n\n\n\n\n\nFor both groups, the residuals vs fitted plots do not reveal any significant deviations and show fairly balanced distributions. The Q-Q residual plots show that the majority of the points lie fairly close to the theoretical line, though the ends do slightly flatten out. However, this is to be expected since our data only included top swimmers, limiting the number of values that could be considered extreme. Overall, the residuals do not indicate any problems with the data and therefore the ANOVA assumptions remain valid for both the men and women models.\nOverall, while the p-values were less than 0.05 for both men and women, the resulting Tukey HSD charts revealed that it was only California’s women age group swimmers that were significantly faster than those of the other top swimming states. On the men’s side though California still remains competitive among other states, the performance of its male swimmers are statistically indistinguishable from those in the other top states. This supports our claim that California is still a “powerhouse” state for age group swimming, especially for women’s swimming, though it is not uniquely dominant for men and women both."
  },
  {
    "objectID": "swimmers.html#summary",
    "href": "swimmers.html#summary",
    "title": "Age-Group Swimming",
    "section": "Summary",
    "text": "Summary\nThe goal for this project was to determine if California is still an age group swimming powerhouse, or in other words, if California continues to produce the fastest age group swimmers in country. We measured this by comparing the average power index of the top 50 male and female swimmers within the six states with at least 50 athletes in the top 100 ranked swimmers. These states included California, Texas, Florida, Virginia, North Carolina, and Pennsylvania, all of which have been in the conversation of best age group swimming state at some point in recent years. We then conducted two separate ANOVA tests for men and women, which produced low p-values of approximately 0.002 and 0 respectively, following them with separate Tukey HSD tests to discover if California was significantly faster than any of the other states.\nAfter analyzing the two separate Tukey plots, we were able to conclude that while California’s men have no significant difference in power index between those of the other top states, California’s women appear to be statistically faster than every other top state. Not one of the five confidence intervals included a difference of 0 on the women’s side, providing strong evidence that California continues to remain dominant in women’s age group swimming, both in quantity and overall quality. For men, California actually had a lower average power index than Texas and Florida, and though the confidence interval included 0, it shows that California’s male swimming scene may no longer have the clear edge it once had on other states.\nThough our findings appear fairly strong, it is important to take the conclusions with a grain of salt. First, our sample was not random, as it only included the top 50 swimmers from only six states, from just this year’s graduating class. While this was a justifiable and deliberate limitation to focus on the elite talent of top states, it does limit the generalizability to the much larger age group swimming world, especially for smaller states. For example, a really small state like Rhode Island or even Washington D.C., as the formerly referenced SwimSwam article mentioned, could have a very small number of swimmers, yet they could all be ranked in the top 100 in the country. This would definitely place them in a better position than California, which has a large number of athletes in the top 1000 but also a huge number of overall swimmers. Additionally, the usage of the power index may not capture the full talent or performance of an individual swimmer. While the power index ranks swimmers by looking at their top 5 events, it does not capture other important metrics such as development trajectory, stroke specialization, and event depth.\nIn the future, a major way of expanding on this work would be to investigate the per-capita proportions of top swimmers in each state. This may provide a better picture of whether or not a state could be considered a “powerhouse” in the age group swimming world. One may also consider looking at trends over time, focusing on if California’s elite talent has been declining over the past few years, or if it jumps around on a yearly basis due to variance. All of these future ideas can be taken further by looking beyond just the current class of graduation high school seniors and instead looking at multiple different years. There is much more complex data to be found by analyzing the trends of development for each state, as a huge aspect of swimming revolves around training and growth over long periods of time. In terms of California swimming, continuing to investigate the disparities between men and women’s programs would provide some insight into why women seem to be faster relative to the rest of the country, and if that pattern exists in other classes. Finally, as stated in the last paragraph, coming up with a new, unique way of analyzing swim talent may help with providing a better picture of swimming performance per state without relying solely on an individual’s top 5 times.\nOverall, the results of this project support the argument that California continues to be a powerhouse in junior age group swimming, though its dominance in both men and women swimming is not absolute. As other smaller states continue to develop their competitive swimming pipelines and programs, the age group swimming scene in the United States will likely continue to shift and change each year."
  },
  {
    "objectID": "swimmers.html#data",
    "href": "swimmers.html#data",
    "title": "Age-Group Swimming",
    "section": "Data",
    "text": "Data\nRaw CSV files can be found in the website’s public repository on github!\nAll data is publicly available and collected from swimcloud.com"
  },
  {
    "objectID": "registration.html",
    "href": "registration.html",
    "title": "5C Fall 2025 Pre-Registration",
    "section": "",
    "text": "This data was gathered over the course of pre-registration week at the Claremont Colleges, from April 22, 2025, to April 24, 2025. Variables included with the data were the course name and code, the timestamp the data was collected, the number of seats filled, and other information about the course such as the subject, area, campus, department, and number of credits. The first graph shows how the rate at which courses became closed increased each day. The second plot simply visualizes the number of full-credit courses offered at each campus of the Claremont Colleges, highlighting the differences in size. For more information about the Fall 2025 pre-registration at the Claremont Colleges, check out the article, “Spring 2025 pre-registration wrapped,” written by Brecken Enright, Jessica Levin, and myself, published by The Student Life.\n\n\nShow the code\nfulldf &lt;- read_csv(\"/Users/tommy/Desktop/TSL/Registration/Tommy_Registration/spring-registration-2025-full.csv\")\n\nnum_closed &lt;- fulldf |&gt;\n  group_by(DateTime) |&gt;\n  summarize(closed = sum((course_status == \"C\") & (seats_filled &gt;= seats_total)))\n\nstart &lt;- as.POSIXct(\"2025-04-22 08:00:00\",\n                    tz = \"America/Los_Angeles\")\n\n\nggplot(num_closed, aes(x = DateTime, y = closed)) +\n  geom_line(color = \"blue\", linewidth = 1.7) +\n  geom_vline(xintercept = as.POSIXct(\"2025-04-22 08:00:00\", tz = \"America/Los_Angeles\"), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\",\n           x = as.POSIXct(\"2025-04-22 9:00:00\",\n                          tz = \"America/Los_Angeles\"),\n           y = 700,            \n           label = \"Start of Senior \\nRegistration\", hjust = 0, size = 3.5, family = \"Palatino\") +\n  geom_vline(xintercept = as.POSIXct(\"2025-04-23 08:00:00\", tz = \"America/Los_Angeles\"), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\",\n           x = as.POSIXct(\"2025-04-23 9:00:00\",\n                          tz = \"America/Los_Angeles\"),\n           y = 700,            \n           label = \"Start of Sophomore \\nRegistration\", hjust = 0, size = 3.5, family = \"Palatino\") +\n  geom_vline(xintercept = as.POSIXct(\"2025-04-24 08:00:00\", tz = \"America/Los_Angeles\"), color = \"red\", linetype = \"dashed\") +\n  annotate(\"text\",\n           x = as.POSIXct(\"2025-04-24 9:00:00\",\n                          tz = \"America/Los_Angeles\"),\n           y = 700,            \n           label = \"Start of Freshmen \\nRegistration\", hjust = 0, size = 3.5, family = \"Palatino\") +\n  scale_y_continuous(limits = c(0, 750),\n                     breaks  = seq(0, 750, by = 100)) +\n  scale_x_datetime(\n    breaks = seq(from   = start,\n                 to     = max(num_closed$DateTime),   # or a hard date\n                 by     = \"8 hours\"),\n    timezone     = \"America/Los_Angeles\",   # &lt;-- converts tick labels\n    date_labels  = \"%b %d\\n%I:%M %p\"           # e.g. \"Apr 23\\n01:00\"\n  ) +\n  labs(\n    x = \"\",\n    y = \"Number of Courses\",\n    title = \"Courses Closed During Fall 2025 Pre-Registration\"\n  ) +\n  theme_minimal(base_family = \"Palatino\") +\n  theme(plot.title = element_text(size = 18))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nnum_courses &lt;- fulldf |&gt;\n  filter((campus == \"HM\" & credits == 3.00) | (campus != \"HM\" & credits == 1.00)) |&gt;\n  group_by(campus) |&gt;\n  summarize(num_courses = (n_distinct(course_code))) |&gt;\n  filter(campus != \"CG\")\n  \nggplot(num_courses, aes(x = campus, y = num_courses, fill = campus)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(\n    values = c(\n      \"CM\" = \"#981a31\", \n      \"HM\" = \"#FDB913\",\n      \"PO\" = \"#0057b8\", \n      \"PZ\" = \"#f7941d\",\n      \"SC\" = \"#34715B\"\n    ),\n    name = \"Campus\"\n  ) +\n  scale_x_discrete(labels = c(\"CM\" = \"Claremont McKenna\", \"HM\" = \"Harvey Mudd\", \"PO\" = \"Pomona\", \"PZ\" = \"Pitzer\", \"SC\" = \"Scripps\")) +\n  labs(\n    x = \"\", y = \"Number of Courses\",\n    title = \"Number of Full-Credit Courses Offered by Campus\",\n    subtitle = \"Fall 2025\"\n  ) +\n  theme_minimal(base_family = \"Palatino\") +\n  theme(plot.title = element_text(size = 18))\n\n\n\n\n\n\n\n\n\nEnright, Brecken. Levin, Jessica. Matheis, Tommy. 2025. “Spring 2025 pre-registration wrapped.” The Student Life Newspaper, April 25. https://tsl.news/spring-2025-pre-registration-wrapped/."
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Guessing on a Test",
    "section": "",
    "text": "Many students have considered the option at once in their academic careers: “Do I simply just guess on every question of the test?” While achieving a perfect score by guessing on a test is an amazing feat, it is pretty simple to calculate. Assuming multiple-choice tests with 4 choices for each question and 10 questions, this simulation study will determine the probability of passing a test by guessing on every question. In this scenario, passing will be considered a C- (70%) or above. The function will return True or False depending on whether or not the test passed. Using a logical map, the function will be iterated 1000 times to determine a probability of passing.\n\n\nShow the code\ntest &lt;- function(questions, choices, grade){\n  num_correct &lt;- sum(sample(1:choices, questions, replace = TRUE) == 1) \n  return((num_correct / questions) &gt;= grade)\n}\n\nset.seed(47)    #Setting seed for reproducibility\ntest_simulation &lt;- map_lgl(1:1000, ~ test(10, 4, .7)) |&gt;\n  mean() |&gt;\n  print()\n\n\n[1] 0.007\n\n\nFor this simulation, 7 out of 1000 tests passed when guessing on all 10 questions, giving a probability of about 0.7%. Not a very great strategy. We can also test different factors, changing the grade required to “pass”, the number of questions, and the number of choices for each question. Let’s do a few more tests where only 60% is required to pass.\n10 Questions, 4 Choices, 60% to Pass:\n\n\nShow the code\nset.seed(47)\ntest_simulation &lt;- map_lgl(1:1000, ~ test(10, 4, .6)) |&gt;\n  mean() |&gt;\n  print()\n\n\n[1] 0.026\n\n\nA little better, 2.6% chance of passing, but only if you’re OK with a 60%.\n20 Questions, 4 Choices, 60% to Pass:\n\n\nShow the code\nset.seed(47)\ntest_simulation &lt;- map_lgl(1:1000, ~ test(20, 4, .6)) |&gt;\n  mean() |&gt;\n  print()\n\n\n[1] 0\n\n\nYikes, just increasing the number of questions to 20 decreases the probability to a 0% chance of passing if you’re just guessing.\nHere is a plot displaying how the number of questions affects the probability of passing, when only 60% is needed to pass:\n\n\nShow the code\n#Re-writing our test_simulation as a function\n\npass_probability &lt;- function(num_questions, num_simulations, num_choices, pct_grade){\n  test_simulation &lt;- map_lgl(1:num_simulations, ~ test(num_questions, num_choices, pct_grade))\n  return(mean(test_simulation))\n}\n\nset.seed(47)\nresults &lt;- map_dbl(1:20, ~ pass_probability(.x, 1000, 4, .60))\n\nresults_table &lt;- tibble(results) |&gt; \n  mutate(questions = c(1:20)) |&gt;\n  as.data.frame()\n\nggplot(results_table, aes(x = questions, y = results)) +\n  geom_smooth(se = FALSE, method = \"loess\", formula = y ~ x) +\n  geom_point() +\n  geom_line() +\n  labs(\n    x = \"Number of Questions\",\n    y = \"Probability of Passing\",\n    title = \"Probability of Passing a Test by Guessing\"\n  ) +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nAs seen above, as the number of questions on a test increases, the probability of passing a test by guessing on every question decreases significantly. For any number of questions beyond 10, it becomes extremely close to 0. The blue line represents the overall trend in the data.\nOverall, the simulation study found that guessing on a test is simply not a good strategy, even when just trying to pass a test. When simulating 1000 times, a probability of 0.7% was found for getting 70% on a 10 question test by guessing. When a 60% was required to pass there was a 2.6% chance, and when increasing the number of questions to 20 there was a 0% chance of passing. Plotting the results of simulating different numbers of questions on the tests revealed the inverse relationship between probability of passing and the number of questions."
  },
  {
    "objectID": "runners.html",
    "href": "runners.html",
    "title": "Start-Line Positions",
    "section": "",
    "text": "(Theoretical) Request for Funds\nTo detect a meaningful difference of 80 seconds in lag between local and non-local runners, assuming a standard deviation of about 160 seconds, funding sufficient for a total sample size of approximately 126 runners (63 local and 63 non-local) is requested. This calculation is based on achieving 80% power with a significance level of \\(\\alpha\\) = 0.05. The value 80 was chosen based on the thought that 80 seconds of lag would be enough to make a difference in race placements for a majority of competitors.\n\n\nIntroduction\nWhen thousands of runners gather for large races, many competitors are forced to start farther back from the starting line than others, often taking up to four or five minutes just to reach the initial starting line. During the Cherry Blossom Ten Mile Run held in Washington D.C. every April, most runners experience at least some delay from when the race starts until they cross the starting line, a result of the massive number of people participating in the event. Usually referred to as lag, this delay can be influenced by several things, for example, their skill level, or more importantly, their position from the starting line.\nThough the starting position very obviously affects the time it takes to reach the starting line, what is not immediately obvious are the factors that determine the starting position for each individual. One factor in particular that may influence a runner’s starting position is how local they are. For example, many runners in this specific race live in the surrounding area, which consists of Washington D.C., Virginia, and Maryland, while thousands of other competitors have to travel from farther states or countries. If a runner lives closer, they may end up arriving earlier than other competitors and be more familiar with the surrounding area, starting closer to the front. On the other hand, due to their proximity to the race, they may simply participate just for fun and start closer to the back. Runners that are not local may be unfamiliar with the location and end up starting closer towards the end of the pack, but if they are dedicated enough to fly or drive hours to the race, their dedication might lead them to start right at the front.\nFocusing on these two groups of competitors, local and non-local runners, this project will investigate whether runners start a race in significantly different positions depending on how local they are, measured by their starting lag. After comparing a sample of runners from a prior Cherry Blossom Race, we will be able to come to a conclusion regarding any differences in starting position that may be found. Section 2 of this project describes the methods and details of the sample being used, along with various visual summaries of the data set. Section 3 presents the results, using statistical analysis and inference to determine the implications it has on the overall investigation. Section 4 provides a conclusion to this project, summarizing the findings and providing an insight into possible errors and future directions of this topics.\n\n\nMethods\nTo gather sufficient information to make any claims about the relationship between locality and starting position, data from the 2005 Cherry Blossom 10 Mile Run was used. The data set includes variables consisting of each runner’s state/country of residence, total time, net time, age, and sex. Total time measures the time from when the starting gun was fired to when the runner crossed the finish line, while net time measures when the participant first crossed the starting line to when they crossed the finish line. We are interested in a separate variable known as lag, which can be calculated by subtracting net time from total time. Overall, a large lag indicates a further position from the starting line, while a smaller lag indicates a closer starting position. In order to quickly identify the locality of a runner, we divided runners into two groups, where local runners were those from Washington D.C., Maryland, or Virginia, and non-local runners were all the remaining individuals. Our sample from the data set consisted of 30 runners, where 20 observations were local runners and 10 were non-local runners. The sample was randomly selected from the data set to minimize any potential bias.\nThe visual below displays the distribution of lag in both the local and non-local groups. The blue box plot represents the local runners while the orange box plot represents the non-local runners:\n\n\nShow the code\n#Utilizing a given data set \"TMR.mini\"\n\nggplot(TMR.mini, aes(x=DMV, y=lag, fill=DMV)) +\n  geom_boxplot() +\n  labs(title=\"Comparison of Lag Times by Runner Origin\",\n       subtitle = \"n = 20 local, n = 10 non-local\",\n       x=\"Local?\",\n       y=\"Lag (seconds)\") +\n  scale_fill_manual(values=c(\"orange\",\"skyblue\"),\n                    labels=c(\"Non-local\",\"Local\")) +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nBefore performing any statistical analysis, some observations can still be made. First, it can be seen visually that local runners appear to have higher lag, indicating a further starting position and more variability. Non-local runners seem to have a lower median and smaller spread, potentially indicating less variability among non-local runners. Still, the exact distributions remain unclear, and cannot be determined without further analysis.\nBecause our investigation is dependent on two independent groups, local runners vs. non-local runners, we can compare them using their sample means, which after computing we get two values:\n\\(\\bullet\\) \\(\\bar{X}_{local} = 229.45 \\text{ seconds}\\)\n\\(\\bullet\\) \\(\\bar{X}_{non-local} = 159.70 \\text{ seconds}\\)\nBased off of our sample means, it looks like local runners tend to start farther from the starting line, but we do not know anything for sure yet. We will perform statistical analysis in section 3 to determine whether or not these values are significantly different enough from each other to conclude that local runners start noticeably closer to the starting line than non-local runners.\nAdditionally, though our sample was selected at random to reduce the potential for any bias to occur, some limitations still exist. For example, because of the small sample size consisting of only 30 runners from one specific road race, our ability to generalize any findings to the population of all runners or even another race is limited. Additionally, because the groups within our sample are even smaller, with non-local runners only having 10 observations, assumptions depending on the Central Limit Theorem may be questionable. Because of this, we will first conduct randomization tests to understand how far apart the means of the two groups might be under the null-hypothesis. After that, we will be able to gain a deeper understanding about the significance of our two means in relation to our investigation, without having to make any assumptions about the distribution of our data.\n\n\nData Analysis\nThe goal of this analysis is to determine whether local runners start further behind the starting line than non-local runners, as measured by their lag. A higher lag means a runner started further back, while a lower lag means a runner began closer to the starting line. Our null hypothesis and alternate hypothesis can be written as:\n\\[H_0: \\mu_{local} = \\mu_{non-local}\\] \\[H_A: \\mu_{local} &gt; \\mu_{non-local}\\] Or, because we will be looking at the differences between two means, it is more appropriate to state the hypotheses in terms of the mean difference:\n\\[H_0: \\mu_{d} = 0\\] \\[H_A: \\mu_{d} &gt; 0\\]\nThe null hypothesis states that runner locality has no effect on the starting position, while the alternate hypothesis states that local runners have a greater average lag time and therefore start farther away than non-local runners, which we have chosen after observing \\(\\bar{X}_{local} = 229.45 \\text{ seconds}\\) and \\(\\bar{X}_{non-local} = 159.70 \\text{ seconds}\\).\nTo compare lag times between local and non-local runners, one might initially think to use a two-sample t-test. However, this method is dependent on the assumptions that the sampling distribution of the group means is approximately normal and that the variances are not drastically different. In our case, these assumptions are questionable due to our small, unequal sample sizes of only 20 local runners and 10 non-local runners, and the skewness of our data, as observed in the histograms of our observations below:\n\n\nShow the code\nggplot(local, aes(x = lag)) +\n  geom_histogram(binwidth = 75, color = \"black\", fill = \"skyblue\") +\n  labs(\n    x = \"Lag\",\n    y = \"Frequency\",\n    title = \"Local Runners\",\n    subtitle = \"n = 20\"\n  ) + theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(nonlocal, aes(x = lag)) +\n  geom_histogram(binwidth = 75, color = \"black\", fill = \"orange\") +\n  labs(\n    x = \"Lag\",\n    y = \"Frequency\",\n    title = \"Non-Local Runners\",\n    subtitle = \"n = 10\"\n  ) + theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nIt can clearly be seen that both groups are right skewed, due to a floor at 0, and have small sample sizes, suggesting that we cannot assume that their distributions are normal. Another way of thinking of the distribution is to consider that more runners will be densely centered around the starting line, while there will be less runners the farther back from the starting line we travel. In order to avoid possibly incorrectly assuming normality, we should not use a theory-based two-sample t-test.\nBecause of these concerns, we will instead perform a randomization test. This approach does not rely on the assumption of normality and instead simulates the null hypothesis directly by randomly assigning the “local” and “non-local” labels to the observed lag times, preserving the group sizes. We then compute and keep track of a test statistic for each shuffled data set, generating a null distribution of the chosen test statistic.\nThe first approach we will use will involve performing a randomization test using the differences of the mean lag for each group. Our observed difference of the sample means was:\n\\[\\bar{X}_{local} - \\bar{X}_{non-local} = 229.45 - 159.70 = 69.75\\] After performing a randomization test of 1000 permutations, we can plot a histogram of each \\(\\bar{X}_{local} - \\bar{X}_{non-local}\\), with the red line marking our observed difference:\n\n\nShow the code\n#Utilizing a given data set \"null.sim\"\n\nggplot(as.data.frame(null.sim), aes(x = null.sim)) +\n  geom_histogram(binwidth = 45, color = \"black\", fill = \"skyblue\") +\n  geom_vline(xintercept = 69.75, color = \"red\") +\n  labs(\n    x = \"Difference in Means\",\n    y = \"Frequency\",\n    title = \"Randomization Test\",\n    subtitle = \"n = 1000\"\n  ) + theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nOur histogram of the differences of the means appears to follow the normal distribution, giving us our null distribution, and \\(\\mu_d\\) does appear to be centered around 0. However, our observed value does not seem to be very odd of a result under the null hypothesis.\nTo determine whether or not our observed difference is plausible under the null, we can now compute a p-value by finding the number of times our simulation returned a value greater than or equal to 69.75. If \\(p &lt; 0.05\\), we will reject \\(H_0\\).\n\\[p = \\frac{\\sum (\\bar{X}_{local} - \\bar{X}_{non-local} \\ge 69.75)}{\\text{Total Simulations}} = \\frac{177}{1000} = 0.177\\]\nWith a p-value of 0.177, the probability of observing a difference of the means of lag time between local runners and non-local runners of 69.75 or greater under the null hypothesis is about 17.7%, which is pretty common and could reasonably occur under the null. Because \\(0.177 &gt; 0.05\\), we fail to reject \\(H_0\\), and do not have enough evidence to suggest that local runners have a tendency to start farther away from the starting line than non-local runners.\nAnother way we can use a randomization test in this situation is to perform a randomization test using the t-statistic. Our t-statistic from our observed data can be calculated to find \\(t = -0.975\\).\nOnce again shuffling our sample to create a randomization test of 1000 permutations, we can plot the null distribution of our t-statistics on a histogram, marking our observed t-statistics with a red line:\n\n\nShow the code\n#Once again utilizing a given data set \"sim\"\n\nggplot(sim, aes(x = t)) +\n  geom_histogram(binwidth = 0.6, color = \"black\", fill = \"skyblue\") +\n  geom_vline(xintercept = observed.t, color = \"red\") +\n  labs(\n    x = \"t-statistic\",\n    y = \"Frequency\",\n    title = \"Randomization Test\",\n    subtitle = \"n = 1000\"\n  ) + theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nOnce again, our null distribution appears to be normal, though our observed statistic does not seem to be too unusual when simulated under \\(H_0\\). We can again compute a p-value to determine whether or not we should reject the null hypothesis, rejecting if \\(p , 0.05\\):\n\\[p = \\frac{\\sum (t \\le -0.975)}{\\text{Total Simulations}} = \\frac{178}{1000} = 0.178\\] Confirming the results from our first randomization test, we are left with a p-value of 0.178, meaning the probability of observing a t-statistic of -0.975 or less under the null hypothesis is about 17.8%, which means it not uncommon to observe our data under the null hypothesis. \\(0.178 &gt; 0.05\\), therefore we again fail to reject \\(H_0\\), and can conclude that we do not have enough evidence to suggest that local runners have a tendency to start farther away from the starting line than non-local runners.\n\n\nSummary\nThe goal of this project was to investigate whether local runners tend to have significantly different starting positions in a race compared to non-local runners. We measured this using lag, defined as the difference in time between the official start and the moment a runner crosses the starting line. A higher lag indicates that a runner took longer to cross the starting line, therefore having a starting position farther back. Based on a random sample of 30 runners, where 20 were local and 10 were non-local, we aimed to test whether one group displayed significantly greater lag times.\nAfter calculating the sample means, the local group did have a higher average lag of about 69.75 seconds greater than the non-local group, which pointed to local runners potentially starting farther back than traveling runners. After considering issues such as a small sample size and skewed data, we decided to perform randomization tests instead of a standard two-sample t-test. We used randomization tests to simulate the null hypothesis directly without having to depend on the assumption that are data was normal. After considering our sample mean where local runners had a higher average lag time, we decided to use a directional hypothesis, where the average lag time for local runners was greater than the average lag time for non-local runners.\nWe performed two types of randomization tests, the first one based on the difference in the means of the two groups and the other using the t-statistic. Both methods resulted in the same conclusion, that our observed data did not significantly deviate from our simulated data. The one-sided p-value for the mean difference test was 0.177, along with 0.178 for the t-statistic test. These values tell us that in the world where local runners and non-local runners have the same average lag time, we would see data as extreme or more extreme than our observed data about 18% of the time. Since our observed data has almost a 1 in 5 chance of occurring under our simulated data, we fail to find enough statistical evidence to conclude that local runners start farther from the starting line than non-local participants. This suggests that there may not be any correlation between locality and starting position among runners.\nDespite our findings seeming relatively conclusive that no connection exists between the two variables, it is important to take into account the limitations of this project. Because our data consisted of only 10 non-local runners and 20 local runners, our small sample size may not have been enough to detect a meaningful difference in lag time and instead may have been influenced by natural variability. Additionally, as mentioned previously, our sample only included data from a single race, which limits the ability to generalize it to the entire population of runners in other races.\nA major way to expand on this project in the future would revolve around gathering enough observations to detect a meaningful difference in lag time. This would also include using an equal amount of observations for both local runners and non-local runners, since our sample had twice as many local participants. Utilizing data from various other races would also be greatly beneficial, as it would allow us to generalize our findings to a larger population of runners. Another factor to focus on in the future is to examine the relationship between starting position and other variables. For example, younger runners may be more likely to start farther back, and therefore have greater lag, regardless of where they are from. Finally, it is important to consider the fact that some participants may not get to intentionally choose where they start. For some races, starting position may even be assigned at random, or others may arrive late and be forced to start farther back, once again regardless of if they are a local or not.\nOverall, while we were not able to find sufficient evidence to draw a connection between the starting position of runners and where they are from, the project highlighted the importance of utilizing the appropriate methodology when analyzing data. The implementation of randomization tests allowed us to come to a conclusion without relying on assumptions. With future work involving a greater number of observations, it is possible to further investigate the relationship between runners and their starting positions.\n\n\nReflection\nAfter completing the analysis using a sample of just 30 observations, we then looked at the entirety of the TenMileRace data set, which contains over 8000 observations. This allowed us to determine whether having an adequate sample size to detect a meaningful difference would provide us with stronger evidence towards our hypothesis.\nAfter calculating the lag and whether or not the runner was local for each observation, we performed a standard two-sided t-test. Despite the possibility that our data may still not be normal, the Central Limit Theorem tell us that \\(\\bar{X}\\) will be normal as long as \\(n\\) is sufficiently large, and we have 8636 observations now. Contrary to our t-statistic from our small sample, which was -0.975, our observed t-statistic for the entire data set was -4.68, which is massive difference. The histogram below displays the corresponding t-distribution with 1515 degrees of freedom, with the red line representing our observed t-statistic from the full data set:\n\n\nShow the code\n# Load full dataset\ndata(\"TenMileRace\")\n\n## Filter to remove missing values and calculate lag\nTMR.full &lt;- TenMileRace |&gt;\n  filter(!is.na(net), !is.na(time), !is.na(state)) |&gt;\n  mutate(\n    lag = time - net,\n    DMV = state %in% c(\"DC\", \"MD\", \"VA\")  # TRUE for local runners\n  )\n\nttest &lt;- t.test(lag ~ DMV, data = TMR.full)\nt_val &lt;- ttest$statistic\ndf_val &lt;- ttest$parameter\n\nt_dist_df &lt;- tibble(\n  x = seq(-6, 6, length.out = 1000),\n  density = dt(x, df = df_val)\n)\n\nggplot(t_dist_df, aes(x = x, y = density)) +\n  geom_line() +\n  geom_vline(xintercept = t_val, color = \"red\") +\n  geom_area(data = filter(t_dist_df, x &gt;= t_val),\n            aes(x = x, y = density),\n            fill = \"skyblue\") +\n  labs(title = \"t-Distribution\",\n       subtitle = \"degrees of freedom = 1515\",\n       x = \"t-value\", y = \"Density\") +\n  theme_minimal(base_family = \"Palatino\")\n\n\n\n\n\n\n\n\n\nThis is a drastic difference from our original sample of 30 observations, and this time our p-value was calculated to be \\(p = 0.00\\) with a 95% confidence interval between 13.77 seconds and 33.63 seconds. This means that out of over 1000 permutations of our data, not even one of them had a corresponding t-statistic as extreme or more extreme than our observed value. Additionally we can be 95% confident that the true average difference in lag lies somewhere between about 14 seconds and 34 seconds. This is important to note, as a lag of between 14 and 34 is not large enough to be considered a meaningful difference, though some may argue otherwise. For a majority of runners, a difference of 30 seconds will likely not have a meaningful impact on placement, and would likely go unnoticed over long races.\nThough we calculated a p-value of 0, and therefore have strong statistical evidence to believe that local runners start farther back than non-local runners, the difference is not large enough to be significant. This conclusion supports our result from the smaller sample which suggested no significant difference between the two groups, though some may argue that a lag between 14 and 34 could be a deciding factor in the race. This comparison emphasizes how results obtained from smaller sample sizes can still have relevancy towards a much larger population, depending on one’s choice for the smallest meaningful difference. Though we technically made a type II error in our original project, failing to reject a false null, our methodology and conclusion were still correct. We used randomization tests in order to avoid making an assumption about the normality of our data, and our interpretation correctly followed the corresponding results of those tests. Though we did not find evidence proving a significant difference, we did observe a difference in the correct direction, just not a large enough difference to reject with our small sample size. After using the full data set we were able to confirm that the observed trend was real, but the true difference was indeed too small to be considered meaningful after all.\nOverall, this reflection further established the importance of sample size and the careful selection of methodology. It also showed that revisiting a project when more data becomes available can lead to a better understanding of the originally published results. Finally, both the small sample and full data set point to the same conclusion: while local runners may start slightly farther back than traveling runners, the difference is not significant enough to suggest a significant behavioral divide."
  }
]