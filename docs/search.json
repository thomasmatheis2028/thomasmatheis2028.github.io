[
  {
    "objectID": "ufo.html",
    "href": "ufo.html",
    "title": "UFO Sightings",
    "section": "",
    "text": "This data set consists of over 80,000 documented UFO sightings all over the world. Some variables include country, region, city, time, shape, and length of encounter. This graph compares the number of encounters between each country in the data set, highlighting the stark difference between the amount of sightings in the United States compared to everyone else.\n\n\n\n\n\n\n\n\n\nThe TidyTuesday data can be found at: https://github.com/rfordatascience/tidytuesday/tree/main/data/2019/2019-06-25\nThe original data set, from NUFORC (The National UFO Reporting Center), can be found at: https://nuforc.org/databank/"
  },
  {
    "objectID": "starbucks.html",
    "href": "starbucks.html",
    "title": "Starbucks",
    "section": "",
    "text": "This is the data set from Starbucks’ official 2021 nutritional information. Steamed milk data is omitted from this data set. The vizualization displays the relationship between the amount of sugar in a beverage and its calories. The color is organized by type of milk. It can be seen that drinks with more sugar typically have a higher calorie count.\n\n\n\n\n\n\n\n\n\nThe TidyTuesday data can be found at: https://github.com/rfordatascience/tidytuesday/tree/main/data/2021/2021-12-21\nThe current nutritional information, from the official Starbucks website, can be found at: https://www.starbucks.ie/sites/starbucks-ie-pwa/files/2025-01/Winter%20Beverage%20Nutritionals%20.pdf"
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "Poorly Anonymized NYC Taxi Data",
    "section": "",
    "text": "Background\nIn 2014, New York City released a large dataset containing the details of over 173 million taxi trips. The decision to release the dataset followed a Freedom of Information request submitted by Chris Wong, an open data activist. This dataset included pick-up and drop-off locations, trip times, fares, and “anonymized” driver license numbers. However, Ars Technica later reported that the anonymization was incomplete, making it surprisingly easy to mathematically reverse-engineer and uncover individual drivers’ identities in just a few hours (Goodin 2014). Meanwhile, The Guardian warned that such revelations could compromise not just the drivers’ privacy, but high-profile passengers as well (Hern 2014). This situation highlights a significant topic of data science ethics. On one hand, open data can be incredibly beneficial for urban planning, traffic analysis, and academic research, which may have been the original intention of Chris Wong. On the other hand, the poor anonymization of the data put personal information at risk. As details like trip routes and tips suddenly became exposed to the community, drivers and their passengers had to worry about being identified and facing public scrutiny. This dilemma highlights how the power to collect and share data can inadvertently harm the very people it is meant to benefit.\n\n\nData Collection and Consent\nIn data science, data collection refers to gathering large amounts of information to be used for analysis. This commonly includes people, which introduces the problem that those whose data is being collected consent to it or even know about it. In this example, the New York City Taxi and Limousine Commission (TLC) legally collected taxi trip data for regulatory purposes, so there was no violation in the initial data gathering. This brings up the differences between legally-collected data and ethically-collected data. For example, many passengers and potentially even drivers may not have even known that data was being collected on them during every trip, which raises consent and privacy issues despite the information being collected lawfully. While the TLC did comply with the Freedom of Information request, it’s unclear if drivers were ever fully informed that details, like how much they earned and where they drove, were even a part of the dataset being released. Additionally, Ars Technica points out the existing privacy concerns revolving around the usage of GPS to track taxi driver’s trips and fares. (Goodin 2014) In this sense, the power dynamics heavily favor the TLC, leaving their drivers, and especially passengers, with little say over how their information is used.\n\n\nData Anonymization\nThe practice of removing personal identifiers from a dataset is known as data anonymization, and it is used to prevent individuals from being linked to any data that may have been collected about them. It becomes a major issue when anonymization techniques are weak and it becomes easy to identify people by cross-referencing with other datasets. As mentioned earlier, though the dataset was presented as “anonymized,” Vijay Pandurangan, a software developer, soon discovered that the same algorithm used to hash driver IDs could be used to reverse engineer and identify every medallion and license number in the span of a few hours (Hern 2014). This meant anyone interested could decode the hashed data and cross-reference it with TLC resources to match medallions to specific drivers. The Guardian warned that even passengers’ identities could be inferred with enough cross-referencing, such as matching time and location details to public events (Hern 2014). New York City officials failed to protect their taxi driver’s privacy, with Ars Technica emphasizing that there were various other ways to successfully anonymize the data, for example, assigning “a random number to each hack license number and medallion number and use the substitute numbers throughout the disclosure” (Goodin 2014). This lack of anonymization shows how crucial it is to implement efficient privacy measures, especially when releasing data regarding people’s daily lives and routines.\n\n\nPermission for Using the Data\nThis was touched on in the last paragraph, but in general, permission to use data determines who can collect, access, and distribute said data. A major concern is determining if their is are ethical standards to consider even if one has a legal right to distribute data. In this scenario, The Freedom of Information Law (FOIL) required New York City officials to release some version of the requested data (Hern 2014). However, data science ethics suggest that an organization should go beyond minimum legal requirements and proactively protect individual privacy. The real question is whether the TLC even considered safer methods, such as providing less detailed data or seeking better encryption techniques, before making the dataset public (Goodin 2014). By not doing so, the agency unintentionally enabled widespread privacy invasions, effectively granting permission for others to dig into drivers’ details, which was likely never the original intent.\n\n\nUnintended Uses of the Data\nOnce data is made public, it can be used in ways the original collectors never anticipated. For example, in 2016 census data was used to create a function that predicted an individual’s race based on their last name and address, which employers could then use to discriminate against those who apply for jobs. In this case, the de-anonymized taxi data made it easy to identify where taxi drivers or passengers lived, and even how much money they made/tipped, information that could be used to easily target an individual. While some of the uses might be considered intriguing or even beneficial for academic research, many can be seen as a complete breach of privacy. As The Guardian stated, “anonymized” data can quickly become weaponized in the wrong hands, casting a dark light on how easily open data can turn into targeted surveillance (Hern 2014). This highlights how crucial it is to carefully consider the ethics of a situation to ensure the privacy and safety of the involved parties.\n\n\nCitations\nGoodin, Dan. 2014. “Poorly Anonymized Logs Reveal NYC Cab Drivers’ Detailed Whereabouts.” Ars Technica, June 26. https://arstechnica.com/tech-policy/2014/06/poorly-anonymized-logs-reveal-nyc-cab-drivers-detailed-whereabouts/.\nHern, Alex. 2014. “New York Taxi Details Whizz Around after ‘Anonymised’ Data Release.” The Guardian, June 27. https://www.theguardian.com/technology/2014/jun/27/new-york-taxi-details-anonymised-data-researchers-warn."
  },
  {
    "objectID": "policing.html",
    "href": "policing.html",
    "title": "Analyzing United States Policing Data",
    "section": "",
    "text": "Every Day, police officers throughout the United States make thousands of traffic stops, inderectly compiling millions of pieces of data over the courses of deacdes. The Standford Open Policing Project has 88 data tables, which consist of 42 states, various city police departments, and state patrol records. The data ranges from 1999 to 2020, depending on the table. In this brief analysis, we will look at data from Los Angeles, Chicago, and California State Patrol, gathering information regarding demographics, the violation committed, and frequency of traffic stops.\nFirst, we will look at the demographic distribution over time for traffic stops conducted in the city of Los Angeles, California. While the data set includes information from December of 2009 to June of 2018, the range 2010 - 2017 was used to include all full years of data.\n\nSELECT raw_descent_description AS race,\n       count(*) AS race_count,\n       YEAR(date) AS year\nFROM ca_los_angeles_2020_04_01\nGROUP BY race, year\nHAVING year BETWEEN 2010 and 2017\nORDER BY year, race;\n\n\n\n\n\n\n\n\n\n\nFrom 2010 to 2017, Hispanic individuals were stopped by police more frequently than any other race, with black and white individuals the next most frequent. Races makred as Asian, American Indian, and other were all stopped relatively infrequently. While some people may immediately conclude that police officers in Los Angeles are more likely to stop people of Hispanic descent, it is important to take into consideration the demographic composition of the city itself. The United States Census Bureau lists that Hispanic or Latino individuals make up about 48.6% of the population, more than any other race. The same report lists that white people make up about 25.3% of the population, while those of black descent make up about 9.0% of the population, both much lower than 48.6%.\nNext, we will investigate common traffic violations in Chicago, Illinois. There are dozens of possible violations, so only those with 40,000 or more occurances were taken into account, giving us the top ten most common violations.\n\nSELECT violation AS Violation,\n       count(*) AS Count\nFROM il_chicago_2023_01_26\nGROUP BY Violation\nHAVING Count &gt;= 40000\nORDER BY Count DESC;\n\n\n\n\n\n\n\n\n\nTop 10 Traffic Violations in Chicago\n\n\nDec 2011 - May 2020\n\n\nViolation\nCount\n\n\n\n\nHEADLIGHT TWO REQUIRED-MOTOR VEHICLE\n280628\n\n\nSTOP AT STOP SIGN\n248009\n\n\nLIGHT, TAIL LIGHTS REQUIRED\n110740\n\n\nDRIVING ON SUSPENDED LICENSE\n90483\n\n\nDISPLAY ST REG-FRONT/REAR\n90143\n\n\nDRIVING WHILE USING CELLULAR PHONE PROHIBITED\n67281\n\n\nDISOBEY RED CIRCULAR STEADY SIGNAL STOP\n64055\n\n\nREGISTRATION PLATES\n58338\n\n\nNO VALID REGISTRATION\n51230\n\n\nDISPLAY ST REG-REAR MOTRCYCL/TRLR/SEMI-TRLR\n49153\n\n\n\n\n\n\n\nFailing to have two functional headlights and failing to stop at a stop sign appear to be the two most common traffic violations in Chicago, with over 100,000 more occurances than the third most common violation, which is failing to have two working tail lights. Four common violations all relate to registration: failure to display registration, no valid registration, no registration plates, and failure to display registration, this time for motorcyles and trailers. Some other common ones are driving on a suspended license and driving while using a cellphone.\nLast, we can add up the numbers of stops for each day of the month to see whether or not the California State Patrol tends to conduct more traffic stops at the beginning of the month, end of the month, or somewhere in the middle. Only 30 days were used, instead of 31, due to every month having at least 30 days aside from February.\n\nSELECT EXTRACT(DAY FROM date) AS day,\n       count(*) AS num_stops\nFROM ca_statewide_2023_01_26\nGROUP BY day\nHAVING day &lt;= 30\nORDER BY day;\n\n\n\n\n\n\n\n\n\n\nThere appears to be a slight tendency to conduct more traffic stops during the first few days of the month, with a steep decline during the last few days of the month. The light blue regression line indicates a slight inverse relationship between the day of the month and number of stops. While the differences are not huge, the small trend could have an explation. For example, if quotas happen to exist within an agency, officers may be inclined to complete these quotas as soon as possible, slowly easing off once they have reached it.\nOverall, data gathered from traffic stop reports has the potential to reveal extremely interesting trends. We were able to easily examine the demographic composition of Los Angeles traffic stops, comparing them to the actual demoagraphics of the city. We found that Hispanic individuals get stopped at a more frequent rate than other races, though they make up the majority of the overall population. In Chicago, the most common traffic violations were not having two working head lights and failing to stop at a stop sign, neither of which were very surprising. What was interesting was the violation that ranked fourth in frequency, driving with a suspended license. If almost 100,000 people were pulled over for not having a valid license, one can only imagine the number of people who get away with it and are driving every day. Finally, we discovered that, though small, there is some correlation between the day of the month and the frequency of traffic stops conducted. It was observed that it may be more likely to get pulled over during the first few days of the month compared to the end of the month, though the difference in frequency was not huge.\nSources:\nThe Los Angeles Census data can be found at: https://www.census.gov/quickfacts/fact/table/losangelescountycalifornia/RHI725223#qf-headnote-b\nThe policing database is a compilation of the Standford Open Policing Project, found at https://openpolicing.stanford.edu, and published in Pierson et al. (2020).\nReferences:\nPierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10."
  },
  {
    "objectID": "spotify.html",
    "href": "spotify.html",
    "title": "Spotify",
    "section": "",
    "text": "After viewing my 2024 Spotify Wrapped (pictured above), I questioned the validity of the results that were displayed. Was Drake really one of my top artists? Did I really listen to Dominic Fike more than Twenty One Pilots? Using Spotify’s “Data Request” feature, I was able to receive copies of my streaming history from November 4th, 2023 to November 4th, 2024.\nFirst, I merged the set of three JSON files I received, and converted them into a single csv file to make it easier to work with, reading the csv into a data table:\n\ndf1 &lt;- fromJSON(\"StreamingHistory_music_0.json\")\ndf2 &lt;- fromJSON(\"StreamingHistory_music_1.json\")\ndf3 &lt;- fromJSON(\"StreamingHistory_music_2.json\")\n\nmerged_df &lt;- bind_rows(df1, df2, df3)\n\nwrite.csv(merged_df, \"spotify_data.csv\", row.names = FALSE)\nspotify_csv &lt;- read_csv(\"spotify_data.csv\")\nspotify_data &lt;- spotify_csv |&gt; mutate(endTime = as.Date(endTime))\nhead(spotify_data, 5)\n\n# A tibble: 5 × 4\n  endTime    artistName        trackName      msPlayed\n  &lt;date&gt;     &lt;chr&gt;             &lt;chr&gt;             &lt;dbl&gt;\n1 2023-10-17 Bad Bunny         MONACO            69369\n2 2023-11-04 Twenty One Pilots Heavydirtysoul     2944\n3 2023-11-04 Twenty One Pilots Hometown            874\n4 2023-11-04 Twenty One Pilots Levitate            768\n5 2023-11-04 Twenty One Pilots Ride                917\n\n\nIt can be seen that the “artistsName” and “trackName” variables both contain character strings, which is what we’ll be working with. Just to simplify things, I converted the “endTime” variable from &lt;S3: POSIXct&gt; to &lt;date&gt;. The variable “msPlayed” contains &lt;dbl&gt; values which measure the time listened to a song measured in milliseconds.\nNow we can being working with the strings!\nOne observation I made in the dataset was that many songs have a feature artist, and therefore have “(feat. ‘artist name’)” in the title. We can clean the dataset by removing the features from the track names!\nFirst, let’s look at some examples of what this looks like, using str_detect:\n\nfeature_example &lt;- spotify_data |&gt;\n  filter(str_detect(trackName,\"\\\\(feat.*\\\\)\")) |&gt;\n  select(artistName, trackName)\nhead(feature_example, 5)\n\n# A tibble: 5 × 2\n  artistName             trackName                                        \n  &lt;chr&gt;                  &lt;chr&gt;                                            \n1 Lil Uzi Vert           Neon Guts (feat. Pharrell Williams)              \n2 Metro Boomin           Space Cadet (feat. Gunna)                        \n3 Metro Boomin           Too Many Nights (feat. Don Toliver & with Future)\n4 Gunna                  P power (feat. Drake)                            \n5 A Boogie Wit da Hoodie Drowning (feat. Kodak Black)                     \n\n\nNow, using str_relpace_all to remove all features, and str_trim to remove all spaces after the string:\n\nspotify_data_nofeat &lt;- spotify_data |&gt;\n  mutate(trackName = str_replace_all(trackName,\"\\\\(feat.*\\\\)\", \"\")) |&gt;\n  mutate(trackName = str_trim(trackName))\n\nUsing the same five songs as before, we can now show how the features have been removed:\n\nfeature_example1 &lt;- spotify_data_nofeat |&gt;\n  filter(str_detect(trackName, \"Neon Guts|Space Cadet|Too Many Nights|P power|Drowning\")) |&gt;\n  select(artistName, trackName)\nhead(feature_example1,5)\n\n# A tibble: 5 × 2\n  artistName             trackName      \n  &lt;chr&gt;                  &lt;chr&gt;          \n1 Lil Uzi Vert           Neon Guts      \n2 Metro Boomin           Space Cadet    \n3 Metro Boomin           Too Many Nights\n4 Gunna                  P power        \n5 A Boogie Wit da Hoodie Drowning       \n\n\nBoom! No features! Let’s look at some rows in the data and see if it looks better:\n\nfeature_example2 &lt;- spotify_data_nofeat |&gt;\n  select(artistName, trackName)\nfeature_example2[41:47,]\n\n# A tibble: 7 × 2\n  artistName             trackName                                              \n  &lt;chr&gt;                  &lt;chr&gt;                                                  \n1 A Boogie Wit da Hoodie Drowning                                               \n2 Metro Boomin           Superhero (Heroes & Villains) [with Future & Chris Bro…\n3 Chief Keef             Love Sosa                                              \n4 Drake                  Rich Flex                                              \n5 Future                 Solo                                                   \n6 Metro Boomin           Trance (with Travis Scott & Young Thug)                \n7 Mac Miller             Ayye                                                   \n\n\nUh oh! We didn’t account for features that use “with” instead of “feat.” Also, we can see that some songs use brackets while others use parenthesis. We can use lookarounds and some more regular expressions to account for the variations of “with” that song titles use:\n\nspotify_data_nofeat &lt;- spotify_data_nofeat |&gt;\n  mutate(trackName = str_replace_all(trackName,\"(?&lt;=\\\\s)(\\\\(.*?\\\\)|\\\\[.*?\\\\]|\\\\swith\\\\s)(.*)\", \"\")) |&gt;\n  mutate(trackName = str_trim(trackName))\n\nThe escapes make it look a little messy, but this uses a positive lookbehind to check for a space before matching any text in parenthesis, brackets, or simply “with” with any spaces around it. We replace all of the matches to this pattern with an empty space. Here’s our example again, displaying the updated results:\n\nfeature_example2 &lt;- spotify_data_nofeat |&gt;\n  select(artistName, trackName)\nfeature_example2[41:47,]\n\n# A tibble: 7 × 2\n  artistName             trackName\n  &lt;chr&gt;                  &lt;chr&gt;    \n1 A Boogie Wit da Hoodie Drowning \n2 Metro Boomin           Superhero\n3 Chief Keef             Love Sosa\n4 Drake                  Rich Flex\n5 Future                 Solo     \n6 Metro Boomin           Trance   \n7 Mac Miller             Ayye     \n\n\nThis looks much cleaner now.\nNow that we have a clean data frame containing the artist name, song name, date, and amount of time listened too, we can make some graphs!\nFirst, I want to look at my top five artists by listening time. To do this, we need to add up the total play time each artist received:\n\nmsPlayed_artist &lt;- spotify_data_nofeat |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_msPlayed = sum(msPlayed)) |&gt;\n  arrange(desc(total_msPlayed)) |&gt;\n  head(5)\n\nTime to graph:\n\nggplot(msPlayed_artist, aes(x = fct_reorder(artistName, total_msPlayed), y = total_msPlayed, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Listening Time (ms)\",\n    title = \"My Top Five Spotify Artists by Listening Time\",\n    fill = \"Artist\"\n  ) + coord_flip()\n\n\n\n\n\n\n\n\nWell that’s odd, it looks like my order doesn’t match with what Spotify told me. Twenty One Pilots has significantly more total listening time than Dominic Fike, yet Dominic Fike appears first on the official list.\nWhat if we look at total songs played instead of listening time:\n\ntotal_songs_artist &lt;- spotify_data_nofeat |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_songs = n()) |&gt;\n  arrange(desc(total_songs)) |&gt;\n  head(5)\n\nOnce again graphing:\n\nggplot(total_songs_artist, aes(x = fct_reorder(artistName, total_songs), y = total_songs, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Songs Played\",\n    title = \"My Top Five Spotify Artists by Total Songs Played\",\n    fill = \"Artist\"\n  ) + coord_flip()\n\n\n\n\n\n\n\n\nWell, at least this tells us that something isn’t quite right with how Spotify determines a user’s top artists. Our top 5 artists measured by total songs played is in the same order as when we measure by total listening time, however this time Twenty One Pilots and Dominic Fike are much closer. This tells me that Drake for sure belonged on my Spotify Wrapped, as he ranked 3rd in total songs played and total listening time. I also confirmed my suspicion that I listened to more Twenty One Pilots than any other artist, especially when looking at listening time. One reason for the discrepancy could be the time frame that Spotify uses. My data begins in November of 2023 and ends in November of 2024. It could be possible that Spotify uses data beginning on January 1st of each year. We can use only the songs from January 1st and onwards to see if it significantly changes our results.\nRepeating the process for listening time:\n\nspotify_2024_only1 &lt;- spotify_data_nofeat |&gt;\n  filter(endTime &gt;= \"2024-01-01\") |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_msPlayed = sum(msPlayed)) |&gt;\n  arrange(desc(total_msPlayed)) |&gt;\n  head(5)\n\nggplot(spotify_2024_only1, aes(x = fct_reorder(artistName, total_msPlayed), y = total_msPlayed, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Listening Time (ms)\",\n    title = \"My Top Five Spotify Artists by Listening Time for 2024\",\n    fill = \"Artist\"\n  ) + coord_flip()\n\n\n\n\n\n\n\n\nRepeating the process for total songs played:\n\nspotify_2024_only2 &lt;- spotify_data_nofeat |&gt;\n  filter(endTime &gt;= \"2024-01-01\") |&gt;\n  group_by(artistName) |&gt;\n  summarise(total_songs = n()) |&gt;\n  arrange(desc(total_songs)) |&gt;\n  head(5)\n\nggplot(spotify_2024_only2, aes(x = fct_reorder(artistName, total_songs), y = total_songs, fill = artistName)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Artist\",\n    y = \"Total Songs Played\",\n    title = \"My Top Five Spotify Artists by Total Songs Played for 2024\",\n    fill = \"Artist\"\n  ) + coord_flip()\n\n\n\n\n\n\n\n\nThis data is closer to the official Spotify Wrapped, though still not quite right. When looking at total listening time for 2024, Don Toliver pushes his way up to third on the list, which is where he was officialy ranked. However, when looking at total songs played for 2024, the only time Dominic Fike has outranked Twenty One Pilots, Don Toliver falls places fifth by almost 500 songs.\nOverall, Spotify Wrapped does a good-enough job in the sense that it correctly identified my top artists artists for both total listening time and total songs played. However, the order that it ranked my top five artsits in doesn’t seem to quite line up with my streaming history data. However, as we found above, the time frame of the data can make a big difference in the rankings. My data contained history up until November 4th, and it is likely that Spotify Wrapped, which released on December 4th, utilized that extra month of streaming history that was not included in the files I received. This extra month of missing data could explain some of the differences in rankings I found.\nTo view the data:\nThe three individual .JSON files of my Spotify streaming history and the merged .csv file can be accessed on the public repository for this website!\nhttps://github.com/thomasmatheis2028/thomasmatheis2028.github.io"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thomas Matheis",
    "section": "",
    "text": "Hey! I’m Tommy, a current first year at Pomona College. I love math and data science, and I’m excited to build upon my current knowledge in those fields. Outside of the classroom, I am a diver on Pomona-Pitzer’s Swimming & Diving team. My hobbies include listening to indie music, going on long drives, and mountain biking."
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Guessing on a Test",
    "section": "",
    "text": "Many students have considered the option at once in their academic careers: “Do I simply just guess on every question of the test?” While achieving a perfect score by guessing on a test is an amazing feat, it is pretty simple to calculate. Assuming multiple-choice tests with 4 choices for each question and 10 questions, this simulation study will determine the probability of passing a test by guessing on every question. In this scenario, passing will be considered a C- (70%) or above. The function will return True or False depending on whether or not the test passed. Using a logical map, the function will be iterated 1000 times to determine a probability of passing.\n\ntest &lt;- function(questions, choices, grade){\n  num_correct &lt;- sum(sample(1:choices, questions, replace = TRUE) == 1) \n  return((num_correct / questions) &gt;= grade)\n}\n\nset.seed(47)\ntest_simulation &lt;- map_lgl(1:1000, ~ test(10, 4, .7)) |&gt;\n  mean() |&gt;\n  print()\n\n[1] 0.007\n\n\nFor this simulation, 7 out of 1000 tests passed when guessing on all 10 questions, giving a probability of about 0.7%. Not a very great strategy. We can also test different factors, changing the grade required to “pass”, the number of questions, and the number of choices for each question. Let’s do a few more tests where only 60% is required to pass.\n10 Questions, 4 Choices, 60% to Pass:\n\nset.seed(47)\ntest_simulation &lt;- map_lgl(1:1000, ~ test(10, 4, .6)) |&gt;\n  mean() |&gt;\n  print()\n\n[1] 0.026\n\n\nA little better, 2.6% chance of passing, but only if you’re OK with a 60%.\n20 Questions, 4 Choices, 60% to Pass:\n\nset.seed(47)\ntest_simulation &lt;- map_lgl(1:1000, ~ test(20, 4, .6)) |&gt;\n  mean() |&gt;\n  print()\n\n[1] 0\n\n\nYikes, just increasing the number of questions to 20 decreases the probability to a 0% chance of passing if you’re just guessing.\nHere is a plot displaying how the number of questions affects the probability of passing, when only 60% is needed to pass:\n\n#Re-writing our test_simulation as a function\n\npass_probability &lt;- function(num_questions, num_simulations, num_choices, pct_grade){\n  test_simulation &lt;- map_lgl(1:num_simulations, ~ test(num_questions, num_choices, pct_grade))\n  return(mean(test_simulation))\n}\n\nset.seed(47)\nresults &lt;- map_dbl(1:20, ~ pass_probability(.x, 1000, 4, .60))\n\nresults_table &lt;- tibble(results) |&gt; \n  mutate(questions = c(1:20)) |&gt;\n  as.data.frame()\n\nggplot(results_table, aes(x = questions, y = results)) +\n  geom_smooth(se = FALSE) +\n  geom_point() +\n  geom_line() +\n  labs(\n    x = \"Number of Questions\",\n    y = \"Probability of Passing\",\n    title = \"Probability of Passing a Test by Guessing\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nAs seen above, as the number of questions on a test increases, the probability of passing a test by guessing on every question decreases significantly. For any number of questions beyond 10, it becomes extremely close to 0. The blue line represents the overall trend in the data.\nOverall, the simulation study found that guessing on a test is simply not a good strategy, even when just trying to pass a test. When simulating 1000 times, a probability of 0.7% was found for getting 70% on a 10 question test by guessing. When a 60% was required to pass there was a 2.6% chance, and when increasing the number of questions to 20 there was a 0% chance of passing. Plotting the results of simulating different numbers of questions on the tests revealed the inverse relationship between probability of passing and the number of questions."
  }
]